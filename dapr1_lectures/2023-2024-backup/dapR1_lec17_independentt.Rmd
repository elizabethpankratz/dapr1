---
title: "<b>T-Test: Independent Samples</b>"
subtitle: "<small>Data Analysis for Psychology in R 1<br>Semester 2, Week 7</small>"
author: "<b>Dr Emma Waterston</b>"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    self_contained: true
    css: 
      - un-xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)

options(htmltools.dir.version = FALSE)
#options(digits = 4, scipen = 2)
options(knitr.table.format = "html")

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE, message = FALSE,
  cache = FALSE,
  dev = "png",
  fig.align = 'center',
  fig.height = 5, fig.width = 6,
  out.width = "80%",
  dpi = 300
)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  outfile = "un-xaringan-themer.css"
)
```


```{r preamble, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
library(kableExtra)
library(moderndive)

theme_set(
    theme_classic(base_size = 15) +
    theme(plot.title = element_text(hjust = 0.5))
)
```

# Learning Objectives
- Understand when to use an independent samples $t$-test
- Understand the null hypothesis for an independent sample $t$-test
- Understand how to calculate the test statistic
- Know how to conduct the test in `R`
---
# Topics for Today
- Conceptual background and introduction to our example
- Calculations and `R`-functions
- Assumptions and effect size

---
# Independent T-Test Purpose & Data

- The independent $t$-test is used when we want to test the difference in mean between two measured groups.

- The groups must be independent:
	- No person can be in both groups.

- Examples:
	- Treatment versus control group in an experimental study
	- Married versus not married

- Data Requirements:
  - A continuously measured variable
  - A binary variable denoting groups

---
# t-statistic

$$t = \frac{(\bar{x}_1 - \bar{x}_2) - \delta_0}{SE_{(\bar{x}_1 - \bar{x}_2)}}$$

- Where
  - $\bar{x}_1$ and $\bar{x}_2$ are the sample means in each group
  - $\delta_0$ is the hypothesised population difference in means in the null hypothesis $(\mu_1 - \mu_2)$
  - $SE_{(\bar{x}_1 - \bar{x}_2)}$ is standard error of the difference

- Sampling distribution is a $t$-distribution with $n-2$ degrees of freedom, where $n$ = $n_1 + n_2$.


---
# Standard Error Difference
- First calculate the pooled standard deviation. 

$$s_p = \sqrt\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}$$

- Then use this to calculate the SE of the difference.

$$SE_{(\bar{x}_1 - \bar{x}_2)} = s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$$

---
# Hypotheses
.pull-left[

- Two-tailed:
$$
\begin{matrix}
H_0: \mu_1 = \mu_2 \\
H_1: \mu_1 \neq \mu_2
\end{matrix}
$$

- One-tailed:

$$
\begin{matrix}
H_0: \mu_1 = \mu_2 \\
H_1: \mu_1 < \mu_2 \\
H_1: \mu_1 > \mu_2
\end{matrix}
$$
]

.pull-right[

- Two-tailed:
$$
\begin{matrix}
H_0: \mu_1 -\mu_2 = 0 \\
H_1: \mu_1 - \mu_2 \neq 0 
\end{matrix}
$$

- One-tailed:

$$
\begin{matrix}
H_0: \mu_1 -\mu_2 = 0 \\
H_1: \mu_1 - \mu_2 < 0 \\
H_1: \mu_1 - \mu_2 > 0
\end{matrix}
$$
] 
---
class: center, middle

# **Questions?**

---
# Example
- Example taken from Howell, D.C. (2010). *Statistical Methods for Psychology, 7th Edition*. Belmont, CA: Wadsworth Cengage Learning.

- Data from Aronson, Lustina , Good, Keough , Steele and Brown (1998). Experiment on stereotype threat.
	- Two independent groups college students (n=12 control; n=11 threat condition). 
	- Both samples excel in maths.
	- Threat group told certain students usually do better in the test

---
# Data

```{r, echo = FALSE}
threat <- tibble(
  Group = as_factor(c(rep("Threat", 11), rep("Control", 12))),
  Score = c(7,5,6,5,6,5,4,7,4,3,6,10,11,8,9,12,11,10,9,8,7,11,9)
)
threat
```

---
# Visualizing data 
- We spoke earlier in the course about the importance of visualizing our data.

- Here, we want to show the mean and distribution of scores by group.

- So we want a.....

---
# Visualizing data 

.pull-left[
```{r, eval=FALSE, echo = TRUE}
ggplot(data = threat, 
       aes(x = Group,  y = Score, fill = Group)) +
  geom_boxplot() + 
  geom_jitter(width = 0.1)
```
]

.pull-right[
```{r, echo=FALSE}
ggplot(data = threat, aes(x = Group, y = Score, fill = Group)) +
  geom_boxplot() + 
  geom_jitter(width = 0.1)
```
]


---
# Hypotheses
- My hypothesis is that the threat group will perform worse than the control group.
  - This is a one-tailed hypothesis.

- And I will use an $\alpha= .05$


---
class: center, middle

# **Questions?**

---
# Calculation
- Steps in my calculations:
  - Calculate the sample mean in both groups $\bar{x}_1$ and $\bar{x}_2$.
  - Calculate the pooled SD $(s_p)$.
  - Check I know my $n$.
  - Calculate the standard error $(SE)$.

- Use all this to calculate $t$.

---
# Calculation

```{r, echo = FALSE}
calc <- threat %>%
  group_by(Group) %>% #<<
  summarise(
    Mean = round(mean(Score),2),
    SD = round(sd(Score),2),
    n = n()
    )
```

```{r, echo = TRUE}
threat %>%
  group_by(Group) %>% #<<
  summarise(
    Mean = mean(Score),
    SD = sd(Score),
    n = n()
  ) %>%
  kable(digits = 2) %>%
  kable_styling(full_width = FALSE)
```

---
# Calculation

```{r, echo = FALSE}
threat %>%
  group_by(Group) %>% #<<
  summarise(
    Mean = round(mean(Score),2),
    SD = round(sd(Score),2),
    n = n()
  ) %>%
  kable(digits = 2) %>%
  kable_styling(full_width = FALSE)
```

- Calculate pooled standard deviation:

$$s_p = \sqrt\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2} = \sqrt{\frac{(11-1)*1.27^2 + (12-1)*1.51^2}{11+12-2}} = \sqrt{\frac{10*1.27^2 + 11*1.51^2}{11+12-2}} = \sqrt{\frac{41.21}{21}} = 1.401$$
- Calculate the standard error:

$$SE_{(\bar{x}_1 - \bar{x}_2)} = s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} = 1.401 \sqrt{\frac{1}{11}+\frac{1}{12}} = 1.401 * 0.417 = 0.584$$

---
# Calculation

- Steps in my calculations:
  - Calculate the sample mean in both groups - Threat $(\bar{x}_1 = 5.27)$, Control $(\bar{x}_2 = 9.58)$.
  - Calculate the pooled SD $(s_p = 1.401)$.
  - Check I know my $n$ - Threat $(n_1 = 11)$ and Control $(n_2 = 12)$ - $n = 23$.
  - Calculate the standard error $(SE = 0.584)$.  
   
- Use all this to calculate $t$.

$$t = \frac{(\bar{x}_1 - \bar{x}_2) - 0}{SE_{(\bar{x}_1 - \bar{x}_2)}} = \frac{5.27-9.58}{0.584} = -7.38$$
- So in our example $t= -7.38$  
  
- Note: When doing hand calculations there might be a small amount of rounding error when we compare to $t$ calculated in `R`.

---
# Is our test significant?
- We have all the pieces we need:
  - Degrees of freedom =  $n-2 = (12+11)-2 = 23-2 = 21$
  - We have our $t$-statistic (-7.38)
  - Hypothesis to test (one-tailed)
  - $\alpha$ level (.05).

- So now all we need is the critical value from the associated $t$-distribution in order to make our decision.
---
# Is our test significant?

.pull-left[
```{r, echo=FALSE, out.width = '100%'}
ggplot(NULL) +
    stat_function(fun=dt,
                  geom = "line",
                  args = list(df=21)) +
    stat_function(fun = dt, 
                  geom = "area",
                  xlim = c(qt(0.05, 21), -8),
                  alpha=.25,
                  fill = "blue",
                  args = list(df=21)) +
    xlim(-8, 8) +
    geom_vline(xintercept = -7.38, col="red") +
    xlab("\n t") +
    ylab("") +
    ggtitle("t-distribution (df=21); t-statistic (-7.38; red line)")
```

]

.pull-right[

```{r, echo=TRUE}
tibble(
  LowerCrit = round(qt(0.05, 21),2),
  Exactp = 1-pt(7.3817, 21)
)
```

]

---
# Is my test significant?
- So our critical value is -1.72
	- Our $t$-statistic (-7.38) is larger than this
	- So we reject the null hypothesis since $p < .001$

---
# Our Test: In R

.pull-left[
```{r, echo = TRUE}
res <- t.test(threat$Score ~ threat$Group, 
       alternative = "less",
       mu = 0,
       var.equal = TRUE,
       conf.level = 0.95)
res
```

]

.pull-right[

To get **missing** CI - need to do a **two-sided** test

```{r eval=FALSE, echo = TRUE}
t.test(threat$Score ~ threat$Group, 
       alternative = "two.sided",
       mu = 0,
       var.equal = TRUE,
       conf.level = 0.95)
```

]

---
# Write up
An independent sample $t$-test was used to determine whether the average maths score of the stereotype threat group $(n = `r calc[1,4]`)$ was significantly lower $(\alpha = .05)$ than the control group $(n = `r calc[2,4]`)$. There was a significant difference in test score between the control $(M = `r calc[2,2]`, SD=`r calc[2,3]`)$ and threat $(M = `r calc[1,2]`, SD=`r calc[1,3]`)$ groups, where the scores were significantly lower in the threat group $(t(`r res$parameter`)=`r round(res$statistic,2)`, p < .001, one-tailed)$. Therefore, we can reject the null hypothesis. The direction of difference supports our directional hypothesis and indicates that the threat group performed more poorly than the control group.


---
class: center, middle

# **Questions?**

---
# Assumption checks summary 

```{r tbl7, echo = FALSE}
tbl7 <- tibble::tribble(
~` `, ~`Description`, ~`One-Sample  t-test`, ~`Independent Sample t-test`, ~`Paired Sample t-test`,
"Normality","Continuous variable (and difference) is normally distributed.","Yes (Population)","Yes (Both groups/ Difference)","Yes (Both groups/ Difference)",
"Tests:","Descriptive Statistics; Shapiro-Wilks Test; QQ-plot"," "," "," ",
"Independence","Observations are sampled independently.","Yes","Yes (within and across groups)","Yes (within groups)",
"Tests:","None. Design issue."," "," "," ",
"Homogeneity of variance","Population level standard deviation is the same in both groups.","NA","Yes","NA",
"Tests:","F-test"," "," "," ",
"Matched Pairs in data","For paired sample, each observation must have matched pair.","NA","NA","Yes",
"Tests:","None. Data structure issue."," "," "," "
)


kable(tbl7) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, font_size = 18)
```


---
# Assumptions
- The independent sample $t$-test has the following assumptions:
	- Independence of observations within and across groups.
	- Continuous variable is approximately normally distribution **within both groups**.
	  - Equivalently, that the difference in means is normally distributed.
	- Homogeneity of variance across groups.

---
#  Assumption checks: Normality 
- Descriptive statistics:
  - Skew:
	  - Below are some rough guidelines on how to interpret skew.
	  - No strict cuts for skew - these are loose guidelines.

```{r echo=FALSE}
library(kableExtra)

tribble(~"Verbal label", ~"Magnitude of skew in absolute value",
       "Generally not problematic", "| Skew | < 1",
       "Slight concern", " 1 > | Skew | < 2",
       "Investigate impact", "| Skew | > 2") %>%
  kable() %>%
  kable_styling(full_width = FALSE)
```

---

# Skew

```{r, echo = TRUE}
library(psych)
threat %>%
  group_by(Group) %>%
    summarise(
      skew = round(skew(Score),2)
  )
```

---
# Histograms

.pull-left[
```{r, eval=FALSE, echo = TRUE, out.width = '100%'}
ggplot(threat, aes(x=Score)) +
  geom_histogram() +
  facet_wrap(~ Group)  + 
  labs(title = "Histogram")
```

]

.pull-right[
```{r, echo=FALSE, out.width = '100%'}
ggplot(threat, aes(x=Score)) +
  geom_histogram() +
  facet_wrap(~ Group) + 
  labs(title = "Histogram")
```
]

---

# Density

.pull-left[
```{r, eval=FALSE, echo = TRUE, out.width = '100%'}
ggplot(threat, aes(x=Score)) +
  geom_density() +
  facet_wrap(~ Group) + 
  labs(title = "Density")
```
]

.pull-right[
```{r, echo=FALSE, out.width = '100%'}
ggplot(threat, aes(x=Score)) +
  geom_density() +
  facet_wrap(~ Group)  + 
  labs(title = "Density")
```
]

---
#  Assumption checks: Normality 
- QQ-plots:
	- Plots the sorted quantiles of one data set (distribution) against sorted quantiles of data set (distribution).
	- Quantile = the percent of points falling below a given value.
	- For a normality check, we can compare our own data to data drawn from a normal distribution

---
# QQ-plots

.pull-left[
```{r, eval=FALSE, echo = TRUE, out.width = '100%'}
ggplot(data = threat, 
       aes(sample = Score, colour = Group)) +
  geom_qq() +
  geom_qq_line() +
      labs(title="QQ-plot", 
       subtitle="The closer the data fit to the line the more normally \ndistributed they are",
       x = "Theoretical quantiles",
       y = "Sample quantiles")
```
]

.pull-right[

```{r, echo=FALSE, out.width = '80%'}
ggplot(threat, aes(sample = Score, colour = Group)) +
  geom_qq() +
  geom_qq_line() +
      labs(title="QQ-plot", 
       subtitle="The closer the data fit to the line the more normally \ndistributed they are",
       x = "Theoretical quantiles",
       y = "Sample quantiles")
```

]

- This looks reasonable in both groups

---
#  Assumption checks: Normality 
- Shapiro-Wilks test:
	- Checks properties of the observed data against properties we would expected from normally distributed data.
	- Statistical test of normality.
	- $H_0$: data = a normal distribution.
	- $p$-value $< \alpha$ = reject the null, data are not normal.
		- Sensitive to $n$ as all $p$-values will be.
		- In very large $n$, normality should also be checked with QQ-plots alongside statistical test.


---
#  Shapiro-Wilks in R
.pull-left[

```{r, echo = TRUE}
threat %>% 
  filter(Group == "Control") %>% 
  pull(Score) %>%
shapiro.test()
```

$W = 0.96, p = .716$

]

.pull-right[
```{r, echo = TRUE}
thr <- threat %>% 
  filter(Group == "Threat") %>% 
  select(Score)
shapiro.test(thr$Score)
```

$W = 0.94, p = .518$

]
---
#  Assumption checks: Homogeneity of variance 
- The $F$-test is a test that compares the variances of two groups.
  - This test is preferable for $t$-test.
	- $H_0$: Population variances are equal.
	- $p$-value $< \alpha$ = reject the null, the variances differ across groups.

---
#  F-test R
```{r echo = TRUE}
var.test(threat$Score ~ threat$Group, ratio = 1)
```

- Why `ratio = 1`?

.pull-left[
  - $H_0: \sigma_1^2 = \sigma_2^2$ 
  - $H_1: \sigma_1^2 \neq \sigma_2^2$
]  

.pull-right[
  - $H_0: \frac{\sigma_1^2}{\sigma_2^2} = 1$ 
  - $H_1: \frac{\sigma_1^2}{\sigma_2^2} \neq 1$
] 
---
#  Violation of homogeneity of variance 
- If the variances differ, we can use a Welch test.

- Conceptually very similar, but we do not use a pooled standard deviation.
	- As such our estimate of the SE of the difference changes
	- As do our degrees of freedom

---
#  Welch test
- If the variances differ, we can use a Welch test.

- Test statistic = same:

$$t = \frac{(\bar{x}_1 - \bar{x}_2) - \delta_0}{SE_{(\bar{x}_1 - \bar{x}_2)}}$$

- SE calculation:

$$SE_{(\bar{x}_1 - \bar{x}_2)} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$$

- And degrees of freedom (don't worry, not tested):

$$df = \frac{(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2})^2}{\frac{(\frac{s_1^2}{n_1})^2}{n_1 -1} + \frac{(\frac{s_2^2}{n_2})^2}{n_2 -1}}$$

---
# Welch: In R

```{r echo = TRUE}
t.test(threat$Score ~ threat$Group, 
       alternative = "less",
       mu = 0,
       var.equal = FALSE, #default, only here to highlight difference
       conf.level = 0.95)
```
---
#  Cohen's D: Independent samples t-test

- Independent-sample $t$-test (if you do have equality of variances):

$$
D = \frac{(\bar{x}_1 - \bar{x}_2) - \delta_0}{s_p}
$$
  - $\bar{x}_1$ = mean group 1
  -	$\bar{x}_2$ = mean group 2
  - $\delta_0$ is the hypothesised population difference in means in the null hypothesis $(\mu_1 - \mu_2)$
  -	$s_p$ = pooled standard deviation

- Independent-sample $t$-test (if you do not have equality of variances):
  - Calculate via `cohens_d()` function from `effectsize` package in `R` - do not calculate by hand.

- Recall the common "cut-offs" for $D$-scores:

| Verbal label         | Magnitude of $D$ in absolute value |
|:--------------------:|:-----------------:|
| Small (or weak)      | $\leq 0.20$       |
| Medium (or moderate) | $\approx 0.50$    |
| Large (or strong)    | $\geq 0.80$       |

---
# Cohen's D in R

.pull-left[

```{r, warning=FALSE, echo = TRUE}
library(effectsize)
cohens_d(threat$Score ~ threat$Group, 
         mu = 0, 
         alternative = "less", 
         var.equal = TRUE, 
         conf.level = 0.95)
```

]
.pull-right[

To get **missing** CI - need to do a **two-sided** test:

```{r eval=FALSE, echo = TRUE}
t.test(threat$Score ~ threat$Group, 
       alternative = "two.sided",
       mu = 0,
       var.equal = TRUE,
       conf.level = 0.95)
```

]

---
# Write up: Assumptions
The DV of our study, Score, was measured on a continuous scale, and data were independent (participants belonged to one of two groups - Control or Threat). The assumption of normality was visually assessed (via histograms, density plots, and a QQplot) as well as statistically via a Shapiro-Wilks test. The QQplots did not show much deviation from the diagonal line in either group, and the Shapiro-Wilks test for both the Control $(W = 0.96, p = .716)$ and Threat $(W = 0.94, p = .518)$ conditions suggested that the samples came from a population that was normally distributed. This was inline with the histogram and density plots for each group, which suggested that Score was normally distributed (and where $skew < 1$). Based on the results of our $F$-test, there was no significant difference between the two population variances $(F(10,11) = 0.71, p = .604)$. The size of the effect was found to be large $D = -3.08~[-5.53,-2.02]$. 

---
# Summary
- Today we have covered:
  - Basic structure of the independent-sample $t$-test
  - Calculations
  - Interpretation
  - Assumption checks
  - Effect size measures

---
# Tasks 

+ Go to your lab and work on the assessed report  
+ Complete any assigned readings  
+ Go to office hours if you have questions  
  + Emma's Office Hours = Tuesdays 10:30-11:30 in G15, 7 George Square  
+ Complete the weekly quiz  
  + Opens Monday at 9am  
  + Closes Sunday at 5pm  