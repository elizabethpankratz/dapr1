---
title: "<b>Week 9: Discrete Probability Distributions </b>"
subtitle: "Data Analysis for Psychology in R 1<br><br> "
author: "Marju Kaps"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
    base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r premable, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(patchwork)
library(moderndive)
library(forcats)
knitr::opts_chunk$set(dev = 'svg')
```


```{r, echo = F}
redText <- function(x) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", '#BF1932', x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", '#BF1932',
      x)
  } else x
}
```

# Course Overview

.pull-left[

```{r echo = FALSE, results='asis'}
block1_name = "Exploratory Data Analysis"
block1_lecs = c("Research design and data",
                "Describing categorical data",
                "Describing continuous data",
                "Describing relationships",
                "Functions")
block2_name = "Probability"
block2_lecs = c("Probability theory",
                "Probability rules",
                "Random variables (discrete)",
                "Random variables (continuous)",
                "Sampling")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")
course_table(block1_name,block2_name,block1_lecs,block2_lecs,week=8)
```


]

.pull-right[


```{r echo = FALSE, results='asis'}
block3_name = "Foundations of inference"
block3_lecs = c("Confidence intervals",
                "Hypothesis testing (p-values)",
                "Hypothesis testing (critical values)",
                "Hypothesis testing and confidence intervals",
                "Errors, power, effect size, assumptions")
block4_name = "Common hypothesis tests"
block4_lecs = c("One sample t-test",
                "Independent samples t-test",
                "Paired samples t-test",
                "Chi-square tests",
                "Correlation")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")
course_table(block3_name,block4_name,block3_lecs,block4_lecs,week=0)
```

]


---



# Learning Objectives
1. Understand concept of a random variable

2. Understand the process of assigning probabilities to all outcomes

3. Apply the understanding of discrete probability distributions to the example of the binomial distribution

4. Understand the difference between a probability mass function (PMF) and a cumulative probability function (CDF)

---
## Probability as it relates to Psychology...


+ Recall our definition of a **random experiment:** 
    + It could (theoretically) be infinitely repeated under the same conditions
    
    + The outcome is uncertain

+ When we conduct a random experiment, we are sampling simple events from a *sample space* to get an outcome

+ We can't be 100% certain which outcome will occur each time the experiment is repeated 

+ An outcome's probability provides us with information that can be used to make decisions about data when we're faced with randomness


---
## Probability as it relates to Psychology...

.pull-left[
+ *Sample Space:* all student eye colours

+ *Simple Event:* the eye colour of an individual student

+ *Random Experiment:* Randomly selecting a student and checking their eye colour
]

.pull-right[

**DapR Student Eye Colours**
```{r, echo = F, fig.height=4.5}
dat <- read.csv('https://uoepsy.github.io/data/surveydata_allcourse.csv')

dat <- dat[dat$eyecolour!='other',]
dat <- dat[!is.na(dat$eyecolour),]

eyeDat <- tibble(EyeColour=dat$eyecolour,
                 x = c(rep(1:17, each = 22)),
                 y = rep(1:22, 17))

ggplot(eyeDat, aes(x, y, colour = EyeColour)) + geom_point(size = 5) +
  scale_colour_manual(values=c('#A64B17','#549299', '#583B2D', '#59725D', '#8C8C8C','#716F3F')) +
  labs(colour='Eye Colour') +
  theme(axis.text = element_blank(), axis.title = element_blank(),
        axis.ticks = element_blank(), panel.background = element_blank(),
        legend.text = element_text(size = 12), 
        legend.title = element_text(size = 14, face = 'bold'))

```

]


---
## Random variables

.pull-left[

+ A **random variable** is a set of values that quantify the outcome of the random experiment
  
  + Allows you to map the outcomes of a random experiment to numbers
  
  + Usually denoted with a capital letter
  
]

--

.pull-right[

**Random Experiment:** Checking eye colour

**Random Variable:**

$$X = \begin{cases}1\ if\ amber \\2\ if\ blue\\3\ if\ brown\\4\ if\ green\\5\ if\ grey\\6\ if\ hazel \end{cases}$$
]

--

- A **discrete random variable** can assume only a finite number of different values
  
  - e.g. outcome of a coin toss; number of children in a family

--

- A **continuous random variable** is arbitrarily precise, and thus can take all values in some range
  
  - e.g. height, age, distance
  
--
  
> **Test your understanding:** What kind of variable is eye colour?

---
## Probability distributions
- A probability distribution maps the values of a random variable to the probability of it occurring

.center[
```{r, echo = F, warning = F, fig.height = 4}

ggplot(eyeDat, aes(x=fct_infreq(EyeColour), y = after_stat(count)/sum(after_stat(count)), fill = EyeColour)) + geom_bar() +
  labs(x='Eye Colour', y = '') + 
  scale_fill_manual(values=c('#A64B17','#549299', '#583B2D', '#59725D', '#8C8C8C','#716F3F')) +
  theme(legend.position = 'none', 
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))
```
]

  

---
## Probability Mass Function


+ A **probability mass function** gives the probability that a **discrete random variable** exactly equals a specific value:

<br>

$$f(x) = P(X=x)$$
<br>
--

+ In the case of our eye colour example:

$$f(hazel) = P(X = hazel)$$

---
## Probability Mass Function

$$f(x) = P(X=x)$$
.pull-left[


+ Some observations (remember probability rules from last week):

  + If you have a random experiment with N possible outcomes, then:
  $$\sum_{i=1}^{N}(f(x_{i}))=1$$
  
  + For any subset A of the sample space:
  $$P(A)=\sum_{i \in A}(f(x_{i}))$$

]

--

.pull-right[

$$P(hazel)=\sum_{i \in hazel}(f(h_i))$$
```{r, echo = F, fig.height = 4}
ggplot(eyeDat, aes(x, y, colour = EyeColour)) + geom_point(size = 5) +
  scale_colour_manual(values=c('#D8D9D7','#D8D9D7', '#D8D9D7', '#D8D9D7', '#D8D9D7','#716F3F')) +
  labs(colour='Eye Colour') +
  theme(axis.text = element_blank(), axis.title = element_blank(),
        axis.ticks = element_blank(), panel.background = element_blank(),
        legend.position = 'none')
```
$$P(hazel) = P(h_1) + P(h_2)...+ P(h_{43}) = \frac{43}{374}$$
        
]


???

i.e., the probability of subset A is the sum of the probabilities of all the simple events x within A.


---

## Discrete random variables: An example

+ **Simple Experiment:** Rolling two 6-sided dice

--

+ **Discrete random variable:** The sum of the two upward facing sides

--

- **Assumptions:**
  1. Dice are fair (numbers between 1 and 6 all equally likely)
  2. The outcome of each dice is *independent* of the outcome of the other

---
## Discrete random variables: An example

.pull-left[

**Sample space**, $S$:

```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics('figures/DiceSampleSpace.png')
```
]

--

.pull-right[
+ We can represent $S$ as a frequency distribution.

+ **Frequency distribution:** Mapping the values of the random variable with how often they occur


```{r, echo=FALSE}
table_data <- as.data.frame(outer(1:6, 1:6, '+') %>%
                              table)

colnames(table_data) <- c('Outcome', 'Frequency')

kable(t(table_data)) %>%
  column_spec(column = 1, bold = T)
```
]

---
count: false

## Discrete random variables: An example

.pull-left[

**Sample space**, $S$:

```{r, echo=FALSE, out.width='85%'}
knitr::include_graphics('figures/DiceSampleSpace.png')
```
]

.pull-right[
+ We can represent $S$ as a frequency distribution.

+ **Frequency distribution:** Mapping the values of the random variable with how often they occur


```{r, echo=FALSE}
table_data <- as.data.frame(outer(1:6, 1:6, '+') %>%
                              table)

colnames(table_data) <- c('Outcome', 'Frequency')

kable(t(table_data)) %>%
  column_spec(column = 1, bold = T)
```


+ Probabilities are just frequency over total possible outcomes:
$$P(x) = \frac{ways\:x\:can\:happen}{total\:possible\:outcomes}$$

> **Test Your Understanding:** What is the probability of the dice summing to `7`?

]

---
## Discrete random variables: An example

.pull-left[
+ First, we need to **sum the frequencies** to the get total number of possible outcomes:

```{r, echo=T}
sum(table_data$Frequency)
```

]


--

.pull-right[


+ Next, we **divide the frequency of each outcome by the total frequency**:

$$P(X=2) = \frac{1}{36} = .03 \\P(X=3) = \frac{2}{36} = .06 \\\vdots \\P(X=12) = \frac{1}{36} = .03$$
]

--

+ This gives us a **discrete probability distribution:**
 
```{r, echo=F}
table_data$Probability <-  round(table_data$Frequency/36, 2)
table_data$Frequency <- as.factor(table_data$Frequency)

kable(t(table_data)) %>%
  column_spec(column = 1, bold = T)
```


---
## Probability mass function
- You can plot a discrete probability distribution using a bar plot: 

.center[

```{r, echo = F}
kable(t(table_data)) %>%
  column_spec(column = 1, bold = T)
```

```{r, echo=FALSE, fig.height=3.75, fig.width = 7}
table_data %>%
  ggplot(., aes(x=Outcome, y=Probability)) + 
  geom_bar(stat='identity', color = 'white', fill='steelblue4') +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 16, face = 'bold'))
```
]

---
class: center, middle

# Questions?

---
## Binomial Distributions
+ A common type of discrete probability distribution is the **binomial distribution**

+ Properties:
  + There are only two possible outcomes, one reflecting `success` and one reflecting `failure`
  + The number of observations (*n*) is fixed
  + Each observation is independent of each other
  + The probability of success (*p*) is the same for each observation

--

+ We are interested in the number of successes (*k*) given a fixed number of trials (*n*)

--

> **Test your understanding:** Identify `success` and $n$ in the following examples:

>   + The number of tails in a sequence of 5 coin tosses

--

>   + The incidence of a disease in a sample of 100 participants


---
## Binomial Probability Mass Function
$$
P(X = k) = \binom{n}{k}p^{k}q^{n-k}
$$

- $k$ = number of `successes`
- $n$ = total trials 
- $p$ = probability of `success`
- $q$ = $1-p$, i.e. probability of `failure`
- $\binom{n}{k}$ = $n$ choose $k$, or the number of ways to select $k$ `successes` from $n$ observations (aka a *combination*).

---
## Binomial PMF - Worked Example

$$
P(X = 3) = \binom{n}{k}p^{k}q^{n-k}
$$

+ **Example:**
  + Random Experiment - Participants were asked to guess which hand a coin is in 5 times.
  + We want to calculate the probability of the participant selecting the correct hand 3 times of the 5
  
+ This looks overwhelming, but let's break it down into it's separate parts.

> Step 1 - Identify $n$, $p$, $q$, and $k$ and plug them into the equation

--

> + $n$ = 5
> + $p$ = 0.5
> + $q$ = 0.5
> + $k$ = 3

---
## Binomial PMF - Worked Example

$$
P(X = 3) = \binom{5}{3}\times0.5^{3}\times0.5^{5-3}
$$
.pull-left[

> Step 2 - $\binom{5}{3}$

+ Reflects the number of ways we could get 3 `successes` from 5 trials

+ This could happen in multiple ways
]

--
.pull-right[

| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |
|---------|---------|---------|---------|---------|
| `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  | N  | N  |
| `r redText('Y')`  | `r redText('Y')`  | N  | `r redText('Y')`  | N  |
| `r redText('Y')`  | `r redText('Y')` | N  | N  | `r redText('Y')` |
| `r redText('Y')`  | N  | `r redText('Y')`  | `r redText('Y')`  | N  |
| `r redText('Y')`  | N  | `r redText('Y')`  | N  | `r redText('Y')`  |
| `r redText('Y')`  | N  | N  | `r redText('Y')`  | `r redText('Y')`  |
| N  | `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  | N  |
| N  | `r redText('Y')`  | `r redText('Y')`  | N  | `r redText('Y')`  |
| N  | `r redText('Y')`  | N  | `r redText('Y')`  | `r redText('Y')`  |
| N  | N  | `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  |

]

---
count: false

## Binomial PMF - Worked Example

$$
P(X = 3) = \binom{5}{3}\times0.5^{3}\times0.5^{5-3}
$$
.pull-left[

> Step 2 - $\binom{5}{3}$

+ Reflects the number of ways we could get 3 `successes` from 5 trials

+ This could happen in multiple ways

+ We could calculate this by hand, but it's much easier to use the formula for $\binom{n}{k}$:

 $$\binom{n}{k} = \frac{n!}{k!(n-k)!}$$


]

.pull-right[

| Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 |
|---------|---------|---------|---------|---------|
| `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  | N  | N  |
| `r redText('Y')`  | `r redText('Y')`  | N  | `r redText('Y')`  | N  |
| `r redText('Y')`  | `r redText('Y')` | N  | N  | `r redText('Y')` |
| `r redText('Y')`  | N  | `r redText('Y')`  | `r redText('Y')`  | N  |
| `r redText('Y')`  | N  | `r redText('Y')`  | N  | `r redText('Y')`  |
| `r redText('Y')`  | N  | N  | `r redText('Y')`  | `r redText('Y')`  |
| N  | `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  | N  |
| N  | `r redText('Y')`  | `r redText('Y')`  | N  | `r redText('Y')`  |
| N  | `r redText('Y')`  | N  | `r redText('Y')`  | `r redText('Y')`  |
| N  | N  | `r redText('Y')`  | `r redText('Y')`  | `r redText('Y')`  |

]

---

## Binomial PMF - Worked Example Step 2

$$\binom{5}{3} = \frac{5!}{3!(5-3)!}$$

$$5! = 5*4*3*2*1 = 120$$

--


$$\binom{5}{3}=\frac{5!}{3!(5-3)!} = \frac{5!}{3!2!} = \frac{120}{6\times 2} = 10$$

+ There are 10 ways to get 3 `successes` from 5 trials

---
## Binomial PMF - Worked Example Steps 3 & 4

$$
P(X = 3) = 10 \times 0.5^{3} \times 0.5^{5-3}
$$
--

> Step 3 - $p^{k}$

+ $0.5^3 = 0.125$

--

> Step 4 - $q^{n-k}$

+ $0.5^{5-3} = 0.5^2 = 0.25$


---
## Binomial PMF - Worked Example Step 5

> Step 5 - Put it all together

$$
P(X = 3) = 10 \times 0.125 \times 0.25 = 0.3125
$$
--

+ Congratulations! We've worked out the probability of one possible outcome ( $X=3$ ) of our random experiment!

--
... but we still have 5 more.

| $k$ | $P(X=k)$ |
|-----|----------|
|  0  |     ?    |
|  1  |     ?    |
|  2  |     ?    |
|  3  |   .3125  |
|  4  |     ?    |
|  5  |     ?    |


---
## Binomial PMF in R

+ Luckily, you can use the `dbinom` function in R to calculate these things for you:

```{r, eval = F}
dbinom(x, size, prob)
```

+ Where:
  + `x` = $k$
  + `size` = $n$
  + `prob` = $p$
  
--

```{r}
dbinom(3, 5, 0.5)
```

---
class: center, middle

# Questions?

---
## Visualising binomial probability distribution

.pull-left[
+ We can pass these values to `ggplot` to produce a bar plot that shows the binomial probability distribution for this random experiment:

```{r, echo = F}
k <- 0:5
df <- data.frame(k=k, Pk=dbinom(k, 5, .5))

df %>%
  kable(digits = 2)
```
]

.pull-right[
```{r, echo=FALSE, fig.height=5}

(pmf <- ggplot(df, aes(x = as_factor(k), y = Pk)) + 
  geom_bar(stat = "identity", fill = "lightblue") + 
  labs(x = "Successes (Out of 5 Trials)", y = 'Probability')) +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))
```
]

---
## Cumulative probability

.pull-left[
+ We've been looking at the **probability mass function** to investigate the total probability of a discrete outcome.

+ The **Cumulative distribution function** allows us to see the total probability of all values before or after a given point.

+ With a binomial distribution, the cumulative probability function simply sums the probabilities of the individual outcomes.

+ In R, we can use `pbinom` to get cumulutive probabilities:

```{r}
round(pbinom(0:5, 5, 0.5), 2)
```


]


.pull-right[
```{r, echo=FALSE, fig.height=4, fig.width = 7}
df$cuPK <- pbinom(k, 5, 0.5)

(cdf <- ggplot(df, aes(x = k, y = cuPK)) + 
  geom_step(stat = "identity") + 
  labs(x = 'Successes (Out of 5 Trials)', y = 'Probability') +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold')))

```
]


---
## Interpreting CDF

.pull-left[
+ **A** reflects the probability of selecting the correct hand 0, 1, or 2 out of five trials

  + In this example, 50%
  
+ **B** reflects the individual probability of selecting the correct hand 3 out of 5 trials

  + The difference between the probability of selecting the correct hand 0, 1, 2, or 3 trials and the probability of selecting the correct hand 0, 1, or 2 trials
  
  + $`r round(df$cuPK[4], 2)`-`r round(df$cuPK[3], 2)` = `r df$cuPK[4]-df$cuPK[3]`$
]

.pull-right[
```{r, echo=FALSE, fig.height=4}
cdf + 
  annotate(geom = 'segment', x=0, xend = 2, y = df$cuPK[3], yend = df$cuPK[3], color = '#BF1932', linetype = 'dashed') +
  annotate(geom = 'text', label = 'A',  x=1, y = .53, color = '#BF1932', size = 6) +
  annotate(geom = 'segment', x=2.75, xend = 2.75, y = df$cuPK[3], yend = df$cuPK[4], color = '#BF1932') +
  annotate(geom = 'segment', x=2.65, xend = 2.85, y = df$cuPK[4], yend = df$cuPK[4], color = '#BF1932') +
  annotate(geom = 'text', label = 'B', x=2.6, y = .68, color = '#BF1932', size = 6)
```
]


---
class: center, middle

# Questions?

---
# Summary of today

We discussed:

- Random variables and random experiments

- Assigning probabilities to outcomes and defining a probability distribution 

- Probability mass functions vs. cumulative distribution functions

- The binomial distribution for assigning probabilities to sets of outcomes

--

<br>

+ Tomorrow, I'll present a live R session focused on computing and plotting discrete probability distributions

+ Next week, we will talk about continuous probability distributions


---
# This week

<script src="https://cdn.jsdelivr.net/npm/iconify-icon@2.1.0/dist/iconify-icon.min.js"></script>

.pull-left[
<iconify-icon icon="clarity:tasks-solid" width="64" height="64"  style="color: #0F4C81"></iconify-icon>

## Tasks

- Attend both lectures

- Attend your lab and work together on the lab tasks

- Complete the weekly quiz
    + Opened Monday at 9am
    + Closes Sunday at 5pm
    
<!-- - Submit Formative Report A by 12 noon on Friday the 18th of October 2024 -->
<!-- - Submit Formative Report B by 12 noon on Friday the 29th of November 2024 -->
<!-- - Submit Formative Report C by 12 noon on Friday the 14th of February 2025 -->
<!-- - Submit the Assessed Report by 12 noon on Friday the 28th of March 2025 -->
]


.pull-right[
<iconify-icon icon="raphael:help" width="64" height="64"  style="color: #0F4C81"></iconify-icon>

## Support

- **Office hours**: for one-to-one support on course materials or assessments<br>(see LEARN > Course information > Course contacts)

- **Piazza**: help each other on this peer-to-peer discussion forum

- **Student Adviser**: for general support while you are at university<br>(find your student adviser on MyEd/Euclid)
]


