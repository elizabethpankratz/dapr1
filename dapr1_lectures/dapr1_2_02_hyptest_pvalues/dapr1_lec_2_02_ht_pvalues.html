<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Hypothesis testing: p-values</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Umberto Noè" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <link href="jk_libs/libs/panelset/panelset.css" rel="stylesheet" />
    <script src="jk_libs/libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="un-xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <b>Hypothesis testing: p-values</b>
## <small>Data Analysis for Psychology in R 1<br>Semester 2, Week 2</small>
### <b>Dr Umberto Noè</b>
### Department of Psychology<br/>The University of Edinburgh

---












# Learning objectives

1. Understand null and alternative hypotheses, and how to specify them for a given research question.

1. Understand the concept of and how to obtain a null distribution.

1. Understand statistical significance and how to calculate p-values from null distributions.


&lt;!-- --- --&gt;
&lt;!-- class: inverse, center, middle --&gt;

&lt;!-- # Part A --&gt;
&lt;!-- ## Introduction --&gt;

---
# Setting

- We cannot afford to collect data for the full population

- Data collected for a random sample of size `\(n\)`

- We are interested in the population mean `\(\mu\)`, but this is unknown as we cannot compute it

- Last week we learned how to:

    + obtain an estimate for the population mean
    + obtain a measure of precision of our estimate
    + report the estimate along with the precision
    + compute and report a range of plausible values for the population mean, called __confidence interval__

---
# Body temperature example

- Today's recurring example will focus on answering the following research question:

&gt; Has the average body temperature for healthy humans changed from the long-thought 37 °C? 

- We will use data comprising measurements on body temperature and pulse rate for a sample of `\(n = 50\)` healthy subjects. Data link: https://uoepsy.github.io/data/BodyTemp.csv

.pull-left[

```r
library(tidyverse)
tempsample &lt;- read_csv('https://uoepsy.github.io/data/BodyTemp.csv')
head(tempsample)
```

```
## # A tibble: 6 × 2
##   BodyTemp Pulse
##      &lt;dbl&gt; &lt;dbl&gt;
## 1     36.4    69
## 2     37.4    77
## 3     37.2    75
## 4     37.1    84
## 5     36.7    71
## 6     37.2    76
```

```r
dim(tempsample)
```

```
## [1] 50  2
```
]

.pull-right[

```r
dim(tempsample)  # both n. rows and n. cols
```

```
## [1] 50  2
```

```r
n &lt;- nrow(tempsample)        # n. rows only
xbar &lt;- mean(tempsample$BodyTemp)
xbar
```

```
## [1] 36.81
```
]



---
# Two hypotheses

- Let's start with an analogy from law. Consider a person who has been indicted for committing a crime and is being tried in a court. 

- Based on the available evidence, the judge or jury will make one of two possible decisions:

    1. The person is not guilty.
    2. The person is guilty.

- Due to the principle of presumption of innocence, at the outset of the trial, the person is presumed not guilty. 

    - "The person is not guilty" corresponds to what is called in statistics the __null hypothesis__, denoted `\(H_0\)`.

- The prosecutor's job is to prove that the person has committed the crime and, hence, is guilty.

    - "The person is guilty" corresponds to what is called in statistics the __alternative hypothesis.__, denoted `\(H_1\)`.

- The evidence that the prosecutor needs to provide must be __beyond reasonable doubt__.


---
# Two hypotheses

- In the beginning of the trial it is assumed that the person is not guilty.

- The null hypothesis `\(H_0\)` is usually the hypothesis that is assumed to be true to begin with. It typically corresponds to "no change", "no effect", "no difference", "no relationship". 

    + It involves the equality symbol `\((=)\)`

    - The null hypothesis usually is the skeptical claim that nothing is different / nothing is happening.

    + Are we considering a (New! Improved!) possibly better method? The null hypothesis says, "Really? Convince me!" To convert a skeptic, we must pile up enough evidence against the null hypothesis that we can reasonably reject it.

- The alternative hypothesis is the claim that we wish to find evidence for. It is typically the hypothesis that embodies the research question of interest.

    + It involves the less than `\((&lt;)\)` or greater than `\((&gt;)\)` or not equal to `\((\neq)\)` symbols.
    + If  `\(H_1\)` uses the symbol `\(&lt;\)`, the test is called left-tailed
    + If `\(H_1\)` uses the symbol `\(&gt;\)`, the test is called right-tailed
    + If `\(H_1\)` uses the symbol `\(\neq\)`, the test is called two-tailed


---
# Test of significance

- A __hypothesis test__ (or __test of significance__) is a procedure for testing a claim about a population parameter (i.e. a property of a population).

- The test works by weighting the evidence __against__ the null (and in favour of the alternative).

    + We want to be sure the sample data provide enough evidence against `\(H_0\)` before rejecting it in favour of `\(H_1\)`.

- The evidence in statistics corresponds to the sample statistic (numerical summary of the sample data). 

    + Informally, people say that the evidence corresponds to the sample data.

- The evidence provided must be __beyond reasonable doubt__. 

    + That is, it should be unlikely for a random sample to give that value of the sample statistic in order to make `\(H_1\)` the explanation for what we observed.
    
    + If it were very likely for a random sample to give that value of the sample statistic, then what we observed could just be a fluke due to random sampling rather than due to `\(H_1\)`.


---
# Body Temperature Example

&gt; Has the average body temperature for healthy humans changed from the long-thought 37 °C? 

- State the hypotheses using proper symbols for the population parameters. 

`$$H_0: \mu = 37$$`
`$$H_1: \mu \neq 37$$`

- From the sample data we can compute the sample mean, which is our estimate of `\(\mu\)`


```r
xbar &lt;- mean(tempsample$BodyTemp)
xbar
```

```
## [1] 36.81
```

- `\(\overline x = 36.81\)`, which differs from 37

- Is this difference large enough to be really due to a systematic shift in the average body temperature of healthy humans?

- Or perhaps can the difference between 36.81 and 37 simply be due to the random sample that we selected?


---
# Null distribution

- The sample mean varies from sample to sample, and all the possible values along with their probabilities form the sampling distribution:
`$$\overline X \sim N(\mu, \frac{\sigma}{\sqrt n})$$`

- If the population mean was truly equal to 37, as the null hypothesis says, how would the sample means look?

- If `\(H_0: \mu = 37\)` is true, the sample mean would follow the distribution:
`$$\overline X \sim N(37, \frac{\sigma}{\sqrt n})$$`

- We can standardise it to obtain a distribution with mean = 0 and SD = 1
$$
\frac{\overline X - 37}{\frac{\sigma}{\sqrt n}} \sim N(0, 1)
$$

---
# Null distribution

- We cannot compute the pop SD `\(\sigma\)` too... Estimate it with sample SD, denoted `\(s\)`. The distribution however becomes a `\(t(n-1)\)`
$$
\underbrace{T = \frac{\overline X - 37}{\frac{s}{\sqrt n}}}_{\textbf{t-statistic}} \sim t(n-1)
$$

- The (above) standardised sample mean using the sample SD `\(s\)` is called the __t-statistic__.

- The distribution of the sample mean __assuming the null hypothesis to be true__ is called the __null distribution__. It tells us which values of  the sample mean we would expect to see if `\(H_0\)` were true.


---
# t-statistic

- For `\(H_0 : \mu = \mu_0\)` the t-statistic is:

`$$t = \frac{\overline x - \mu_0}{\frac{s}{\sqrt n}}$$`

- The __t-statistic__ measures how many standard errors away from `\(\mu_0\)` is our sample mean `\(\overline x\)`.

- The terms t-statistic and __t-value__ are used as synonyms

- When referring to the t-value obtained from the observed sample mean, people often use the word "observed t-value" or "observed t-statistic", but hopefully this is clear from the context.


---
# Visually

.pull-left[
&lt;img src="dapr1_lec_2_02_ht_pvalues_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
Consider `\(H_0 : \mu = \mu_0\)`

`$$t = 0 
\quad \text{when} \quad
\dfrac{\overline x - \mu_0}{\frac{s}{\sqrt n}} = 0 
\quad \text{when} \quad
\bar x = \mu_0$$`

Roughly speaking:

- We are very likely to see a t-value between -1 and 1 if in the population the mean is really 37

- We are less likely to see a t-value between [-2, -1] and [1, 2] if in the population the mean is really 37

- It is very unlikely to see a t-value smaller than -2 or larger than 2 if in the population mean is really 37

]


---
# Visually

.pull-left[
&lt;img src="dapr1_lec_2_02_ht_pvalues_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
- If our random sample leads to an observed t-value that has relatively high probability in the null distribution

    + There are many random samples leading to the same t-value when `\(H_0\)` is true
    
    + Hence, it is very likely to obtain such t-value just from random sampling.
]


---
# Visually

.pull-left[
&lt;img src="dapr1_lec_2_02_ht_pvalues_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
- If our sample leads to an observed t-value that has relatively low probability, 

    + there are very few many random samples leading to the same t-value. 
    
    + The observed t-value is __unlikely__ to be obtained from random samples when `\(H_0\)` is true. That surprisingly high or low t-value could be due to something else (our claim).
]


---
# Evaluating how unlikely

- We need an objective criterion to evaluating how unlikely it is to see the same t-value as the one from the observed sample, if the null hypothesis were true.

- Just plotting a line on a graph can lead to very different conclusions based on the reader's perception of probability and their risk-aversion.


---
# p-value

- In statistics, the evidence against the null hypothesis is provided by data (and not the prosecutor) and we use a probability to say how strong the evidence is.

- The probability that measures the strength of the evidence against a null hypothesis is called a __P-value__.

- The P-value is the probability, computed assuming that `\(H_0\)` is true, of obtaining a t-value __at least as extreme as that observed__.

- Operationally, extreme corresponds to the direction specified by `\(H_1\)`. 

    + If &gt;, find the probability of larger values than that observed
    + If &lt; find the probability of smaller values than that observed
    + If `\(\neq\)` use both tails

- This is called the __P-value__, where the P stands for Probability.



---
# Body temperature example

- We have that `\(\bar x = 36.81\)`. Let's compute the t-statistic, telling us how many SEs away from 37 the value 36.81 is.


```r
xbar &lt;- mean(tempsample$BodyTemp)
s &lt;- sd(tempsample$BodyTemp)
n &lt;- nrow(tempsample)
SE &lt;- s / sqrt(n)

mu0 &lt;- 37  # null hypothesis value

tvalue &lt;- (xbar - mu0) / SE
tvalue
```

```
## [1] -3.141
```


The t-value from the observed sample is
`$$t = -3.141$$`

---
# Body temperature example

- Our alternative is `\(H_1 : \mu \neq 37\)`, so something is very different from that value either  if it's (a) much bigger or (b) much smaller. 

- In terms of t-value, something is very different when it's smaller than -3.141 or larger than 3.141.

- The probability of observing something either larger or smaller is:


```r
#         P(T &lt;= t)            + P(T &gt;= t)
pvalue &lt;- pt(-3.141, df = n-1) + pt(3.141, df = n-1, lower.tail = FALSE)
pvalue
```

```
## [1] 0.002854
```

```r
#         P(T &lt;= t)            + P(T &gt;= t)
pvalue &lt;- pt(-3.141, df = n-1) + (1 - pt(3.141, df = n-1))
pvalue
```

```
## [1] 0.002854
```

- The p-value is: `\(p = 0.003\)`




---
# p-value

- The smaller the p-value, the stronger the evidence that the data provide against `\(H_0\)`.

- Small P-values are evidence against `\(H_0\)`, because they say that the observed result would be unlikely to occur if `\(H_0\)` was true.

- Large P-values fail to provide sufficient evidence against `\(H_0\)` 

- However, we need operational definition for _how small_ a p-value should be to provide sufficient evidence against `\(H_0\)`. How small is small?


---
# Significance level

- We can compare a p-value with some fixed value (called __significance level__ and denoted `\(\alpha\)`) that is in common use as standard for evidence against `\(H_0\)`. 

- The most common fixed values are `\(\alpha = 0.10\)`, `\(\alpha = 0.05\)`, and `\(\alpha = 0.01\)`. 

- The value is chosen by the researcher (__you!__) once for all at the beginning of your study.

- It is important to clearly state the significance level at the start  of your write-ups in every report or journal paper.

- If `\(p \leq 0.05\)`, there is no more than 1 chance in 20 that a sample would give evidence at least this strong just by chance when `\(H_0\)` is actually true. 

- If `\(p \leq 0.01\)`, we have a result that in the long run would happen no more than once per 100 samples when `\(H_0\)` is true. 


---
# Statistical significance: interpretation

- If the p-value `\(\leq \alpha\)`, we say that the data are statistically significant at level `\(\alpha\)`, and we reject `\(H_0\)` in favour of `\(H_1\)`.

    + We say that the sample data provide significant evidence against `\(H_0\)` and in favour of `\(H_1\)`.
    
- If the p-value `\(&gt; \alpha\)`, we say that the data are __not__ statistically significant at level `\(\alpha\)`, and we do not reject `\(H_0\)`.

    + We say that the sample data do not provide sufficient evidence against `\(H_0\)`.

- "Significant" is a technical term in scientific research and it doesn't have the same meaning as in everyday English language. 

    + It does __not__ mean "important".  
    
    + It means "not likely to happen just by chance because of random variations from sample to sample".


---
# Guidelines for reporting strenght of evidence

The following table summarizes in words the strength of evidence that the sample results bring in favour of the alternative hypothesis for different p-values:

| Approximate size of p-value  | Loose interpretation                   |
|:----------------------------:|:---------------------------------------|
| p-value `\(&gt;\)` 0.1              | little or no evidence against `\(H_0\)`    |
| 0.05 `\(&lt;\)` p-value `\(\leq\)` 0.1  | some evidence against `\(H_0\)`            |
| 0.01 `\(&lt;\)` p-value `\(\leq\)` 0.05 | strong evidence against `\(H_0\)`          |
| p-value `\(\leq\)` 0.01          | very strong evidence against `\(H_0\)`     |


---
# Report

- It is important to always report your conclusions in full, without hiding information to the reader.

- Always restate your decision in nontechnical terms andd in the context of the research question.

    + Restate your decision on whether you reject or fail to reject `\(H_0\)` in simple nontechnical terms, making sure to address the original claim, to provide the reader with a take-home message.

- Report as follows: t(`df`) = `tvalue`, p = `pvalue`, `one/two`-sided.

    + t(49) = -3.14, p = .003, two-sided

- Irrespectively of your `\(\alpha\)` level, if your p-value is `\(\geq\)` .001 it is good practice to report it __in full__.

- Irrespectively of your `\(\alpha\)` level, if your p-value is &lt; .001 you can just  report it as p &lt; .001 as people don't really care about 5th or 6th decimal numbers.


---
# Body temperature example

At the `\(\alpha = 0.05\)` significance level, we performed a two-sided hypothesis test against the null that the mean body temperature for all healthy humans is equal to 37 °C.  
The sample results provide very strong evidence against the null hypothesis and in favour of the alternative one that the average body temperature differs from 37 °C ($t(49) = -3.14, p = .003$, two-sided).



---
# Note

- Failing to find sufficient evidence against `\(H_0\)` means only that the data are __consistent__ with `\(H_0\)`, not that we have clear evidence that `\(H_0\)` is true.

- Example: not finding sufficient evidence that person is guilty doesn't necessarily prove they are innocent. They chould have just hidden every single possible trace.

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
