<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 11: Samples, Statistics &amp; Sampling Distributions </title>
    <meta charset="utf-8" />
    <meta name="author" content="Marju Kaps" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b>Week 11: Samples, Statistics &amp; Sampling Distributions </b>
]
.subtitle[
## Data Analysis for Psychology in R 1<br><br>
]
.author[
### Marju Kaps
]
.institute[
### Department of Psychology<br>The University of Edinburgh
]

---








# Course Overview

.pull-left[

&lt;table style="border: 1px solid black;&gt;
  &lt;tr style="padding: 0 1em 0 1em;"&gt;
    &lt;td rowspan="5" style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1;text-align:center;vertical-align: middle"&gt;
        &lt;b&gt;Exploratory Data Analysis&lt;/b&gt;&lt;/td&gt;
    &lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Research design and data&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Describing categorical data&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Describing continuous data&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Describing relationships&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Functions&lt;/td&gt;&lt;/tr&gt;

  &lt;tr style="padding: 0 1em 0 1em;"&gt;
    &lt;td rowspan="5" style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1;text-align:center;vertical-align: middle"&gt;
        &lt;b&gt;Probability&lt;/b&gt;&lt;/td&gt;
    &lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Probability theory&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Probability rules&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Random variables (discrete)&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        Random variables (continuous)&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:1"&gt;
        &lt;b&gt;Sampling&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;


]

.pull-right[


&lt;table style="border: 1px solid black;&gt;
  &lt;tr style="padding: 0 1em 0 1em;"&gt;
    &lt;td rowspan="5" style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4;text-align:center;vertical-align: middle"&gt;
        &lt;b&gt;Foundations of inference&lt;/b&gt;&lt;/td&gt;
    &lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Confidence intervals&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Hypothesis testing (p-values)&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Hypothesis testing (critical values)&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Hypothesis testing and confidence intervals&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Errors, power, effect size, assumptions&lt;/td&gt;&lt;/tr&gt;

  &lt;tr style="padding: 0 1em 0 1em;"&gt;
    &lt;td rowspan="5" style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4;text-align:center;vertical-align: middle"&gt;
        &lt;b&gt;Common hypothesis tests&lt;/b&gt;&lt;/td&gt;
    &lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        One sample t-test&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Independent samples t-test&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Paired samples t-test&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Chi-square tests&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td style="border: 1px solid black;padding: 0 1em 0 1em;opacity:0.4"&gt;
        Correlation&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

]


---



## This Week's Learning Objectives
1. Understand the difference between a population parameter and a sample statistic
2. Understand the concept and construction of sampling distributions
3. Understand the effect of sample size on the sampling distribution
4. Understand how to quantify the variability of a sample statistic and sampling distribution (standard error)

---
## Concepts to carry forward

+ Data can be of different types

--

+ We can assign probabilities to outcomes of random experiments

--

+ We can define a probability distribution that describes the probability of all possible events

--

+ Dependent on type (continuous vs. discrete), we can visualise and describe the distribution of data differently


---
## Why are these concepts relevant to psych stats?

+ In psychology, we design a study, measure variables, and use these measurements to calculate a value that carries some meaning
    + E.g. the difference in reaction times between groups

--

+ Given it has meaning based on the study design, we want to know something about the value:
    + Is it unusual or not?
    + This is the focus throughout the next semester

--

+ **Today:**
    + We will talk about populations, samples, and sampling
    + Basic concepts of sampling may seem simple and intuitive
    + These concepts will be very useful when we start talking about _statistical inference_, or how we make decisions about data

---
## Populations vs Samples
+ In statistics, we often refer to populations and samples
    + **Population:** The entire group of people about whom you'd like to make inferences
    + **Sample:** The subset of the population from whom you will collect data to make these inferences

--

+ To get the most accurate measure of our variable, it would be ideal to collect data from the entire population; however, this is not feasible

--

+ In almost all cases, researchers need to collect data from samples and use these results to make inferences about the population
  + The population value of the variable of interest is known as a **population parameter**
  + The sample value of the variable of interest is known as a **sample statistic**, or **point-estimate**

---
## Populations vs Samples - Notation

.pull-left[
+ It's important to know that although you may have seen these different types of notation used interchangeably in the past, they are actually slightly different when one is referring to a _population_ versus a _sample_:
]


.pull-right[

|Population | Parameter         | Sample   |
|-----------|-------------------|----------|
| `\(\mu\)`     | Mean              | `\(\bar{x}\)`|
| `\(\sigma\)`  | Standard Deviation| `\(s\)`      |
| `\(N\)`       | Size              | `\(n\)`      |

]

---
## Populations vs Samples - Example

+ Suppose I wanted to know the proportion of UG students at the University of Edinburgh who are permanent Scottish residents

.center[
&lt;img src="figures/PopulationMetric.png" width="50%" /&gt;
]

&gt; **Test your Understanding:** What is the population in this example?

--

&gt; What is the variable of interest?

--

&gt; What is the parameter?

---
## Populations vs Samples - Example
+ How can we collect this information? 

--

  + We could send out an email requesting all students to provide their permanent residence...but it's not likely that all students will respond

--

  + We could ask instructors to collect this data from students in their classes, but not every student will attend each class, and not every instructor will comply

--

- Even with this relatively small, accessible population, it's unlikely we can collect information from every single member

---
## Populations vs Samples - Example

- Instead, we have to use the data from students who _do_ respond to make inferences about the overall student population 

.center[
&lt;img src="figures/FullSample.png" width="65%" /&gt;
]


&gt; **Test your Understanding:** What is the sample?

--

&gt; What is the statistic, or the point-estimate?

---
## Parameters, point-estimates, and sampling distributions

.pull-left[
+ It is the population parameter (proportion of UoE students who are permanent Scottish residents) we are interested in. This is a *true* value of the world.

+ We can draw a sample, and calculate this proportion in the sample
  + The point-estimate from the sample is our best guess at the population parameter

]

---
count: false

## Parameters, point-estimates, and sampling distributions

.pull-left[
+ It is the population parameter (proportion of UoE students who are permanent Scottish residents) we are interested in. This is a *true* value of the world.

+ We can draw a sample, and calculate this proportion in the sample
  + The point-estimate from the sample is our best guess at the population parameter

+ If we draw multiple samples, we can produce a **sampling distribution**, which is a probability distribution of some statistic obtained from repeatedly sampling the population 

]

.pull-right[
.center[
![](figures/Samples.png)&lt;!-- --&gt;
]
]

---
## 2021/22 actual proportion

.pull-left[
+ Let's use real data from 21/22 to demonstrate this concept

  + These data represent the entire student body from 21/22

+ Using these data, we can:

  1) Simulate gathering multiple samples of UoE students
  
  2) Calculate the proportion of permanent Scottish residents in each sample
  
  3) Produce a frequency distribution of each sample's proportions

]

.pull-right[

&lt;table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Scottish &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; n &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Freq &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; No &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20090 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.7 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Yes &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8665 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]



---
## Visualising sampling distributions

.pull-left[
+ Imagine we took a single sample of 10 students

+ This demonstrates how a statistic from a single small sample may or may not capture the population parameter
]


.pull-right[.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-7-1.svg)&lt;!-- --&gt;
]]


---
## Visualising sampling distributions

.pull-left[

+ Imagine that we instead took 10 samples of 10 students each

+ What happens to the difference between the mean sampling statistic and the population parameter?

]


.pull-right[
.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-8-1.svg)&lt;!-- --&gt;
]
]

---
## Visualising sampling distributions

+ If we were to repeat this process 2 more times, we can create three sampling distributions, each of which look different.

.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-9-1.svg)&lt;!-- --&gt;
]

--

+ Each sampling distribution is characterising the _sampling variability_ in our estimate of the parameter of interest

--

+ **Do samples with values close to the population value tend to be more or less likely?**


---
## Taking more samples
- So far we have taken 10 samples... what if we took more? 
- Let's imagine we sampled 10 students 100 times

--

.pull-left[
.center[**10 Samples of 10 Students**]
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-10-1.svg)&lt;!-- --&gt;

]
.pull-right[
.center[**1000 Samples of 10 Students**]
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-11-1.svg)&lt;!-- --&gt;
]

--

- **What differences do you notice between these two sampling distributions?**
    
---
## Bigger samples

- We've been taking samples of 10 students. Let's see what happens when we increase our sample size to `\(n = 50\)`, and then `\(n = 100\)`. 

.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-12-1.svg)&lt;!-- --&gt;
]

--

+ **What changes as we increase sample size?**

---
## Properties of sampling distributions
+ Sampling distributions are characterising the variability in sample estimates
    - Variability can be thought of as the spread in data/plots

--

+ So as we increase `\(n\)`, we get less variable samples (the distribution of sample statistics is more tightly clustered around the population parameter

  + Harder to get an unrepresentative sample as your `\(n\)` increases

--

+ Let's put this phenomenon in the language of probability: 

  + As sample `\(n\)` increases, the probability of observing a point-estimate that is a long way from the population parameter (here 0.30) decreases (becomes less probable)

--

+ So when we have large samples, the point-estimates from those samples are likely to be closer to the population value

---
## Standard error
- We can formally calculate the variability of a sampling distribution, or the **standard error**

`$$SE=\frac{\sigma}{\sqrt{n}}$$`

--

- This is essentially calculating the standard deviation of the sampling distribution, with a key difference:
      - The standard deviation describes the variability _within_ one sample
      - The standard error describes variability _across_ multiple samples
      
--

+ With continuous data, the standard error gives you a sense of how different `\(\bar{x}\)` is likely to be from `\(\mu\)`

--

+ In this example, we're working with binomial data (Scottish Residency = Yes or No), so the standard error indicates how greatly a particular sample proportion is likely to differ from the proportion in the population

---
## Properties of sampling distributions

.pull-left[
- Mean of the sampling distribution is close to `\(\mu\)`, even with a small number of samples

- As the number of samples increases:

  + The sampling distribution approaches a normal distribution
  + Sample `\(\bar{x}\)`'s pile up around `\(\mu\)`
    
]

.pull-right[

![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-13-1.svg)&lt;!-- --&gt;

![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-14-1.svg)&lt;!-- --&gt;
]

---
count: false

## Properties of sampling distributions

.pull-left[
- Mean of the sampling distribution is close to `\(\mu\)`, even with a small number of samples

- As the number of samples increases:

  + The sampling distribution approaches a normal distribution
  + Sample `\(\bar{x}\)`s pile up around `\(\mu\)`
    
- As `\(n\)` per sample increases, the SE of the sampling distribution decreases (becomes narrower)
    - With large `\(n\)`, all our point-estimates are closer to the population parameter
]

.pull-right[

![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-15-1.svg)&lt;!-- --&gt;

]

---
## Two Related Concepts

+ These properties illustrate two important concepts:

+ **The Law of Large Numbers:** As `\(n\)` increases, `\(\bar{x}\)` approaches `\(\mu\)`

--

+ **Central Limit Theorem:** When estimates of `\(\bar{x}\)` are based on increasingly large samples ( `\(n\)` ), the sampling distribution of `\(\bar{x}\)` becomes more normal (symmetric), and narrower (quantified by the standard error)

--

+ These concepts hold regardless of the underlying shape of the distribution

+ To demonstrate this, let's explore some different distributions
    
---
## Uniform distribution

.pull-left[
- Continuous probability distribution 

- There is an equal probability for all values within a given range
]

.pull-right[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-16-1.svg)&lt;!-- --&gt;
]


---
## Uniform distribution


.pull-left[
.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-18-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-18-2.svg)&lt;!-- --&gt;
]]

.pull-right[
.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-19-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-19-2.svg)&lt;!-- --&gt;
]]

---
## `\(\chi\)` -square distribution

.pull-left[
+ Continuous probability distribution

+ Non-symmetric
]

.pull-right[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-20-1.svg)&lt;!-- --&gt;
]


---
## `\(\chi\)` -square distribution

.pull-left[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-22-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-22-2.svg)&lt;!-- --&gt;
]

.pull-right[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-23-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-23-2.svg)&lt;!-- --&gt;
]

---
## `\(t\)` -distribution

.pull-left[
+ Continuous probability distribution

+ Symmetric and uni-modal (similar to the normal distribution)

  + "Heavier/fatter tails" = greater chance of observing a value further from the mean
]

.pull-right[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-24-1.svg)&lt;!-- --&gt;
]

---
## `\(t\)` -distribution


.pull-left[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-26-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-26-2.svg)&lt;!-- --&gt;
]

.pull-right[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-27-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-27-2.svg)&lt;!-- --&gt;
]

---
## Central Limit Theorem

+ These examples all demonstrate the Central Limit Theorem
+ When `\(n\)` is large enough, `\(\bar{x}\)`'s approximate a normal distribution around `\(\mu\)`, regardless of the underlying population distribution

.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-28-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-28-2.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-28-3.svg)&lt;!-- --&gt;
]

.center[
![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-29-1.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-29-2.svg)&lt;!-- --&gt;![](dapR1_lec10_Samples-SamplingDist_files/figure-html/unnamed-chunk-29-3.svg)&lt;!-- --&gt;
]

---
## Features of samples
- Is our sample...
    - Biased?
    - Representative?
    - Random?

--

- If a sample of `\(n\)` is drawn at random, it is likely to be unbiased and representative of `\(N\)`

- Our point estimates from such samples will be good guesses at the population parameter

---
## Summary of today
- Samples are used to estimate the population
- Samples provide point estimates of population parameters
- Properties of samples and sampling distributions
- Properties of good samples

---
# This week

&lt;script src="https://cdn.jsdelivr.net/npm/iconify-icon@2.1.0/dist/iconify-icon.min.js"&gt;&lt;/script&gt;

.pull-left[
&lt;iconify-icon icon="clarity:tasks-solid" width="64" height="64"  style="color: #0F4C81"&gt;&lt;/iconify-icon&gt;

## Tasks

- Attend both lectures

- Attend your lab and work together on the lab tasks

- Complete the weekly quiz
    + Opened Monday at 9am
    + Closes Sunday at 5pm
    
- Submit Formative Report B by 12 noon on Friday the 29th of November 2024
&lt;!-- - Submit Formative Report C by 12 noon on Friday the 14th of February 2025 --&gt;
&lt;!-- - Submit the Assessed Report by 12 noon on Friday the 28th of March 2025 --&gt;
]


.pull-right[
&lt;iconify-icon icon="raphael:help" width="64" height="64"  style="color: #0F4C81"&gt;&lt;/iconify-icon&gt;

## Support

- **Office hours**: for one-to-one support on course materials or assessments&lt;br&gt;(see LEARN &gt; Course information &gt; Course contacts)
  + Note: No office hours between 2 Dec and 10 Jan

- **Piazza**: help each other on this peer-to-peer discussion forum

- **Student Adviser**: for general support while you are at university&lt;br&gt;(find your student adviser on MyEd/Euclid)
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
