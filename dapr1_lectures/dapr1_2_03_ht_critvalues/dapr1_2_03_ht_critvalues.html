<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Hypothesis testing: critical values</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Umberto Noè" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <link href="jk_libs/libs/panelset/panelset.css" rel="stylesheet" />
    <script src="jk_libs/libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="un-xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <b>Hypothesis testing: critical values</b>
## <small>Data Analysis for Psychology in R 1<br>Semester 2, Week 3</small>
### <b>Dr Umberto Noè</b>
### Department of Psychology<br/>The University of Edinburgh

---













# Learning objectives

1. Understand the parallel between p-values and critical values

1. Be able to perform a one-sided or two-sided hypothesis test using the critical value method

1. Understand the link between t-scores and critical values


---
class: inverse, center, middle

---
class: inverse, center, middle

# Part A
## Introduction


---
# Setting

- We cannot afford to collect data for the full population

- Data are only collected on __one__ random sample of `\(n\)` individuals, where `\(n\)` = sample size

- After we have selected a sample at random, we know the measurements of the individuals in the sample.

- We are not interested in the individuals in the sample per se, but we collected data on them to __infer__ from the sample data some property of the wider population the sample came from.

- You may want to:

    + Estimate a population parameter
    + Test whether a hypothesised parameter value is plausible


---
# Estimation

- If our goal is estimating a population mean, `\(\mu\)`

+ we use the average of the observations in the sample, `\(\bar x\)`, as the estimate

+ the precision of our estimate is measured by the standard error, telling the average distance of a sample mean from the population mean

+ a 95% (or 90% or 99%) __confidence interval__ gives us a range of plausible values for the population mean. This is:

`$$\left[ \bar x - t^* \cdot \frac{s}{\sqrt n},\ \ \bar x + t^* \cdot \frac{s}{\sqrt n} \right]$$`

---
# Testing

- If our goal is testing a hypothesis, e.g. 
`$$H_0: \mu = \mu_0 \qquad \text{vs} \qquad H_1:\mu \neq \mu_0$$`

+ Compute a __test statistic__, measuring some sort of "distance" between the sample data and the null hypothesis.
    
&gt; __Definition: Test Statistic__  
&gt; A test statistic is any numerical quantity computed from the sample data with the purpose to make a test of some kind.
    
+ For testing a population mean, we use the __t-statistic__:
`$$t = \frac{\bar x - \mu_0}{SE} \qquad \qquad \text{where } SE = \frac{s}{\sqrt n}$$`

+ The t-statistic is the distance of the sample mean from the hypothesised parameter value, measured in units of the standard error.
    
+ When you will perform a test on categorical variables you will see a different type of test statistic (the chi-squared statistic). We use the t-statistic for testing a mean.


---
class: inverse, center, middle

---
class: inverse, center, middle

# Part B
## P-values and Critical Values


---
# Sample mean

- Why is the sample mean a __good estimate__ of the population mean?

- To study this, let's do a thought-experiment that in practice we seldom can do:
    
    + __IF you could afford__ to take not just one sample, but many samples from the population, each of size `\(n\)`.
    
    + You could compute the average of the data in each sample
    
    + You can plot a histogram of those averages
    
    + The centre of the histogram is the same value as the population mean
    
    + The spread of the histogram is the standard error



---
# Thought experiment






.pull-left[
- Suppose I gave you a population __with a mean of 20__:

    (21, 21, 18, 23, 21, 25, 16, 19, 17, 19, 21, 23, 19, 18, 19, 21, 20, 23, 19, 17)

- Take all possible samples of size `\(n = 4\)`.

- Compute the average of the `\(n = 4\)` numbers in each sample.

- Plot all the averages `\(\bar{x}\)`'s using a histogram.

    + Centre?
    + Spread?
    
- The sample mean `\(\bar x\)` fluctuates from sample to sample around the population mean `\(\mu = 20\)`, and the typical distance from the true value is given by the SE
]


.pull-right[
&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-3-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


---
# Testing hypotheses

- Suppose we are testing
`$$H_0 : \mu = 20 \\ H_1 : \mu \neq 20$$`


- We can build a __test statistic__ to assess how much the sample data are consistent with the null hypothesis we specified.

- This takes the form of a distance between the observed and hypothesised mean, measured in units of the SE

- The __test statistic__ for testing a mean is the __t-statistic__ or __t-score__. 
In our case, `\(\mu_0 = 20\)` so:
`$$t = \frac{\bar x - 20}{s / \sqrt  n}$$`

- What is the distribution of the t-statistic __when `\(H_0\)` is true__? I.e., what is the __null distribution__?


---
# Null distribution



.pull-left[
- Suppose I gave you a population __with a mean of 20__:

    (21, 21, 18, 23, 21, 25, 16, 19, 17, 19, 21, 23, 19, 18, 19, 21, 20, 23, 19, 17)

- Take all possible samples of size `\(n = 4\)`.

- __For each sample__:
    
    - Compute the average `\(\bar{x}\)` of the `\(n=4\)` numbers in the sample.
    - Compute the SD `\(s\)` of the `\(n=4\)` numbers in the  sample.
    - Compute the t-statistic `\(t = \frac{\bar x - 20}{s / \sqrt{n}}\)` for that sample.

- Histogram of t-statistics shows a distribution with more variability than a standard normal:
$$
t(n-1)
$$
]

.pull-right[
&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

???

- Instead of computing the t-statistic on one sample only (the one sample we have collected), we can imagine doing this many many times for all possible random samples.

-  You know how to compute a t-score. You need to find the mean and SD of that sample, and do `\(t = \frac{\bar x - \mu_0}{s / \sqrt{n}}\)`. Now think about doing those steps repeatedly on many, many samples from the population. 


---
# Null distribution

- This thought-experiment shows us that the t-statistic, when the null hypothesis is true, follows a `\(t(n-1)\)` distribution.

`$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} \sim t(n-1)$$`

- Why only when `\(H_0\)` is true? Recall the example when `\(\mu_0 = 20\)`. If that is the case, the sampling distribution of the mean will fluctuate around 20, and as such the distances of the  sample means from 20 will fluctuate around 0.

- This shows us all the possible distances (t-statistics) between a sample mean and hypothesised mean when `\(H_0\)` is true.

- If we get a distance (t-statistic) that is unlikely, we start doubting the null hypothesis!



---
# Example

.pull-left[
- Suppose you have collected data on one sample, with sample size 4. The sample data are:
`$$(32, 36, 26, 28)$$`

- We wish to test whether this sample comes from a population with a mean different from 20:
`$$H_0: \mu = 20 \quad \text{vs} \quad  H_1: \mu \neq 20$$`


```r
data_sample &lt;- tibble(x = c(32, 36, 26, 28))
data_sample
```

```
## # A tibble: 4 × 1
##       x
##   &lt;dbl&gt;
## 1    32
## 2    36
## 3    26
## 4    28
```
]

.pull-right[

```r
xbar &lt;- mean(data_sample$x)
xbar
```

```
## [1] 30.5
```


```r
n &lt;- nrow(data_sample)
s &lt;- sd(data_sample$x)
se &lt;- s / sqrt(n)

mu0 &lt;- 20
tobs &lt;- (xbar - mu0) / se
tobs
```

```
## [1] 4.735
```
]


---
# P-value

.pull-left[
- Last week we learned to assess significance not just by placing the observed value of the t-statistic onto the corresponding t-distribution, which is not very objective

- We choose a significance level, `\(\alpha = 0.05\)`  say.

- As `\(H_1\)` is two-sided, we compute the p-value as:


```r
# Twice the area to the right of observed t
pvalue &lt;- 2 * pt(abs(tobs), df = n-1, 
                 lower.tail = FALSE)
pvalue
```

```
## [1] 0.01785
```

]

.pull-right[
&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]



---
# P-value

.pull-left[

- As `\(H_1\)` is two-sided, we compute the p-value as:


```r
# Twice the area to the right of observed t
pvalue &lt;- 2 * pt(abs(tobs), df = n-1, 
                 lower.tail = FALSE)
pvalue
```

```
## [1] 0.01785
```

- This is the probability of observing a t-statistic having at least the same distance from 0 as the observed t-statistic, when `\(H_0\)` is true.

- An observed mean of 30 is as distant from `\(\mu_0 = 20\)` as 10 is.
]

.pull-right[

&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---
# Making a decision

.pull-left[
- To make a decision on whether or not to reject `\(H_0\)` we need to compare the computed p-value with the chosen significance level of 5%.

- As the p-value is 0.018, which is less than the chosen significance level, we reject the null hypothesis.

- In doing so, we compared the blue area, against the "red" area corresponding to the `\(\alpha = 0.05\)` significance level.

- The `\(\alpha = 0.05\)` probability is equally divided among the two tails in this case, because the alternative hypothesis is two-sided:

]

.pull-right[

&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


---
# Equivalent approach!


.pull-left[
- Rather than comparing the area corresponding to `\(\alpha\)` (0.05, in red) to the area corresponding to the p-value (0.018, in blue), we can compare the corresponding t-statistics along the x-axis.

- The p-value is computed using the observed t-statistic, 4.74.

- The t values that cut an area of 0.025 to the left and 0.025 to the right are called the __critical values__ for `\(\alpha = 0.05\)` and denoted `\(-t^*\)` and `\(+t^*\)`:


```r
qt(c(0.025, 0.975), df = n-1)
```

```
## [1] -3.182  3.182
```

- We reject `\(H_0\)` when either `\(t \leq -t^*\)` or `\(t \geq +t^*\)`.

- In this case, `\(t =\)` 4.74 is larger than the critical value `\(\geq t^* =\)` 3.18.
]

.pull-right[
&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]


---
# Example 2

- Suppose now that the collected sample, with sample size 4, was:
`$$(18, 21, 19, 23)$$`

- We wish to test whether this sample comes from a population with a mean different from 20:
`$$H_0: \mu = 20 \\ H_1: \mu \neq 20$$`


```r
data_sample2 &lt;- tibble(x = c(18, 21, 19, 23))
data_sample2
```

```
## # A tibble: 4 × 1
##       x
##   &lt;dbl&gt;
## 1    18
## 2    21
## 3    19
## 4    23
```


---
# Example 2



```r
xbar &lt;- mean(data_sample2$x)
xbar
```

```
## [1] 20.25
```


```r
n &lt;- nrow(data_sample2)
s &lt;- sd(data_sample2$x)
se &lt;- s / sqrt(n)

mu0 &lt;- 20
tobs &lt;- (xbar - mu0) / se
tobs
```

```
## [1] 0.2255
```


---
# Example 2

- Compute the critical values for a `\(t(n-1)\)` distribution with `\(\alpha = 0.05\)`.


```r
tstar &lt;- qt(c(0.025, 0.975), df = n-1)
tstar
```

```
## [1] -3.182  3.182
```

- Is the observed t-statistic `\(t =\)` 0.23 smaller than or equal to the lower critical value? _No!_


```r
tobs &lt;= tstar[1]
```

```
## [1] FALSE
```

- Is the observed t-statistic `\(t =\)` 0.23 greater than or equal to the upper critical value? _No!_


```r
tobs &gt;= tstar[2]
```

```
## [1] FALSE
```


---
# Example 2

- As our observed t-statistic lies in between the two critical values, rather than beyond, it lies in the middle 95% of the null distribution.

- If you were to compute the p-value for `\(t\)`, it would be larger than the area arising from the critical values `\(\pm t_^*\)` (the significance level `\(\alpha\)`).

- We do not have sufficient evidence to reject `\(H_0\)` at the 5% significance level.


---
class: inverse, center, middle

---
class: inverse, center, middle

# Part C
## Body temperature example


---
# Body temperature example

&gt; Has the average body temperature for healthy humans changed from the long-thought 37 °C? 

- We are testing:

`$$H_0: \mu = 37 \qquad \text{vs} \qquad H_1: \mu \neq 37$$`

--

- Read the data:


```r
library(tidyverse)
tempsample &lt;- read_csv('https://uoepsy.github.io/data/BodyTemp.csv')
head(tempsample)
```

```
## # A tibble: 6 × 2
##   BodyTemp Pulse
##      &lt;dbl&gt; &lt;dbl&gt;
## 1     36.4    69
## 2     37.4    77
## 3     37.2    75
## 4     37.1    84
## 5     36.7    71
## 6     37.2    76
```


---
# Body temperature example


```r
xbar &lt;- mean(tempsample$BodyTemp)
xbar
```

```
## [1] 36.81
```

--

- The observed t-statistic: `\(t = \frac{\bar x - \mu_0}{s / \sqrt{n}}\)`


```r
n &lt;- nrow(tempsample)
n
```

```
## [1] 50
```

```r
s &lt;- sd(tempsample$BodyTemp)
SE &lt;- s / sqrt(n)

mu0 &lt;- 37
tobs &lt;- (xbar - mu0) / SE
tobs
```

```
## [1] -3.141
```


---
# Body temperature example

- The observed t-statistic is `\(t=\)` -3.14.

--

- Compute the critical values of a t(49) distribution with `\(\alpha = 0.05\)`:


```r
qt(c(0.025, 0.975), df = n - 1)
```

```
## [1] -2.01  2.01
```

--

- The observed t-statistic lies beyond the critical values, and as such falls in the 5% probability tails of the null distribution.

--

- We reject the null hypothesis as the observed t-statistic is unlikely to be obtained if the null hypothesis were true.

--

- In terms of reporting, you could report the upper critical value only, and report the absolute value of the t-statistic.

--

- At the 5% significance level, we performed a two-sided hypothesis test against the null hypothesis that the mean body temperature for all healthy humans is equal to 37 °C.  
As the observed t-statistics lies beyond the critical values, the sample results provide strong evidence against the null hypothesis and in favour of the alternative one that the average body temperature differs from 37 °C; `\(|t(49)| = 3.14, t^* = 2.01\)`, two-sided.



---
# `\(H_1 : \mu &lt; \mu_0\)`, example with `\(t(3)\)`

&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-26-1.png" width="55%" style="display: block; margin: auto;" /&gt;


---
# `\(H_1 : \mu &gt; \mu_0\)`, example with `\(t(3)\)`

&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-27-1.png" width="55%" style="display: block; margin: auto;" /&gt;


---
# `\(H_1 : \mu \neq \mu_0\)`, example with `\(t(3)\)`

&lt;img src="dapr1_2_03_ht_critvalues_files/figure-html/unnamed-chunk-28-1.png" width="55%" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
