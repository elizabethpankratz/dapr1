<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 16: One-Sample t-test</title>
    <meta charset="utf-8" />
    <meta name="author" content="Tom Booth" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <b>Lecture 16: One-Sample t-test</b>
## Data Analysis for Psychology in R 1<br><br>
### Tom Booth
### Department of Psychology<br>The University of Edinburgh
### AY 2020-2021

---









# Today
- Introduce the three types of `\(t\)`-test:
- Discuss in detail one-sample `\(t\)`-tests
	- When to use
	- Tested hypotheses
	- Calculation
	- Doing in R
	- Write up

---

# Learning objectives
- Understand when to use a one sample `\(t\)`-test
- Understand the null hypothesis for a one sample `\(t\)`-test
- Understand how to calculate the test statistic
- Know how to conduct the test in R

???
Remember to do the course admin shout outs

---

# Purpose
- `\(t\)`-tests (generally) concern testing the difference between two means.
  - One-sample `\(t\)`-tests compare the mean in a sample to a known mean .
  - Independent `\(t\)`-tests compare the means of two independent samples.
  - Paired sample `\(t\)`-tests compare the mean from a single sample at two points in time (repeated measurements)

---

# Data Requirements: One-sample t-test
- A continuous variable.
  - Remember we are calculating means.
- A known mean that we wish to compare our sample to.
- A sample of data from which we calculate the sample mean.

---

# Hypotheses
- We are comparing a single sample mean `\(\mu_1\)` to a known mean `\(\mu\)` 

$$
H_0: \mu = \mu_1
$$

- Note this is identical to saying:


$$
H_0: \mu - \mu_1 = 0
$$

---

# Alternative Hypotheses
- Two-tailed:

$$
`\begin{matrix}
H_0: \mu = \mu_1 \\
H_1: \mu \neq \mu_1
\end{matrix}`
$$

- One-tailed:


$$
`\begin{matrix}
H_0: \mu = \mu_1 \\
H_1: \mu &lt; \mu_1 \\
H_1: \mu &gt; \mu_1
\end{matrix}`
$$

---

# Are these means different?

![](lec16_onesamplet_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;


---

# What about these?

![](lec16_onesamplet_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

---

# Differences in means
- Why can we not tell whether they are different or not?
- What else might we want to know in order to know whether not the group means could be thought of as coming from the same distribution?


---

# All the information

![](lec16_onesamplet_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

---

# All the information

![](lec16_onesamplet_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

---

# t-statistic
- Recall when talking about hypothesis testing:
  - We calculate a test statistic that represents our question.
  - We compare our sample value to the sampling distribution under the null
- Here the test statistic is a `\(t\)`-statistic.


---

# t-statistic

$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}}
$$

- where
  - `\(s\)` = sample estimated standard deviation of `\(x\)`
  - `\(N\)` = sample size
- The numerator = a difference is means
- The denominator = a estimate of variability
- `\(t\)` = a standardized difference in means.

---

# And breath
- **Example:** Suppose I want to know whether the retirement age of Professors in my department is the same as the national average.
- The national average age of retirement for Prof's 65.
- So I look at the age of the last five Prof's that have retired at Edinburgh and compare against this value.

---

# Data


```
## # A tibble: 5 x 2
##   ID      Age
##   &lt;chr&gt; &lt;dbl&gt;
## 1 Prof1    40
## 2 Prof2    70
## 3 Prof3    85
## 4 Prof4    80
## 5 Prof5    75
```

---

# Hypotheses
- Let's say I am new to the department and a priori have no idea of the ages they retired.
- So I specify a two-tailed hypothesis with `\(\alpha\)` = 0.05.
- So I am simply asking, does my mean differ from the known mean.

---

# Calculation

$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}}
$$

- Steps to calculate `\(t\)`:
  - Calculate the sample mean ($\bar{x}$).
  - Calculate the sample standard deviation ($s$).
  - Check I know my N.
  - Calculate the standard error of the mean ($\frac{s}{\sqrt{N}}$).
  - Use all this to calculate t.

---

# Calculation

```r
df %&gt;%
  summarise(
    PopMean = 65,
    Mean = mean(Age),
    SD = sd(Age),
    N = n()
  ) %&gt;%
  mutate(
    SE = SD/sqrt(N)
  )
```

```
## # A tibble: 1 x 5
##   PopMean  Mean    SD     N    SE
##     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
## 1      65    70  17.7     5  7.91
```

---

# Calculation


```
## # A tibble: 1 x 5
##   PopMean  Mean    SD     N    SE
##     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
## 1      65    70  17.7     5  7.91
```


$$
t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{N}}} = \frac{70-65}{\frac{17.7}{\sqrt{5}}} = \frac{5}{7.91} = 0.63
$$

---

# Is our test significant?
- The sampling distribution for `\(t\)`-statistics is a `\(t\)`-distribution.
- The t-distribution is a continuous probability distribution very similar to the normal distribution.
  - Key parameter = degrees of freedom (df)
	- df are a function of N.
	- As N increases (and thus as df increases), the t-distribution approaches a normal distribution.
- For a one sample `\(t\)`-test, we compare our test statistic to a `\(t\)`-distribution with N-1 df.

---

# Is our test significant?
- So we have all the pieces we need:
  - Degrees of freedom = N-1 = 5-1 = 4
  - We have our t-statistic (0.63)
  - Hypothesis to test (two-tailed)
  - `\(\alpha\)` level (0.05).
- So now all we need is the critical value from the associated `\(t\)`-distribution in order to make our decision.

---

# Is our test significant?


```r
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
)
```

```
## # A tibble: 1 x 2
##   LowerCrit UpperCrit
##       &lt;dbl&gt;     &lt;dbl&gt;
## 1     -2.78      2.78
```

---

# Is our test significant?

![](lec16_onesamplet_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;


```
## # A tibble: 1 x 2
##   LowerCrit UpperCrit
##       &lt;dbl&gt;     &lt;dbl&gt;
## 1     -2.78      2.78
```

---

# Is our test significant?
- So our critical value is 2.78
  - Our t-statistic is less than this, 0.63.
  - So we fail to reject the null hypothesis.
- t(4)=0.63, p &gt; .05, two-tailed.


---

# Exact p-values


```r
tibble(
  LowerCrit = round(qt(0.025, 4),2),
  UpperCrit = round(qt(0.975, 4),2),
  Exactp = round(2*(1-pt(0.63, 4)),2)
)
```

```
## # A tibble: 1 x 3
##   LowerCrit UpperCrit Exactp
##       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
## 1     -2.78      2.78   0.56
```


---

# Exact p-values

![](lec16_onesamplet_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;




```
## # A tibble: 1 x 3
##   LowerCrit UpperCrit Exactp
##       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
## 1     -2.78      2.78   0.56
```

---

# In R


```r
t.test(df$Age, mu=65, alternative="two.sided")
```

```
## 
## 	One Sample t-test
## 
## data:  df$Age
## t = 0.63246, df = 4, p-value = 0.5614
## alternative hypothesis: true mean is not equal to 65
## 95 percent confidence interval:
##  48.05027 91.94973
## sample estimates:
## mean of x 
##        70
```

---

# Write up
A one-sample t-test was conducted in order to determine if a statistically significant ( `\(\alpha\)` =.05) mean difference existed between the average retirement age of Professors, and the age at retirement of a sample of 5 psychology Professors. The sample scored higher (Mean=70, SD=17.68) than the population (Mean = 65), however the difference was not statistically significant (t(4)=0.63, p &gt; .05, two-tailed). 

---

# Assumptions
- As noted above, we have some requirements of the data:
  - DV is continuous.
- But we also have some additional model assumptions for the test to be valid.
  - The data are normally distributed.
  - The data are an independent random sample.
- (2) we can not directly test.
- (1) we can test using a QQplot, histograms and a Shapiro-Wilks Test.

---

&lt;iframe src="https://www.menti.com/dahq981cn9" width="100%" height="600px"&gt;&lt;/iframe&gt;

---

&lt;div style='position: relative; padding-bottom: 56.25%; padding-top: 35px; height: 0; overflow: hidden;'&gt;&lt;iframe sandbox='allow-scripts allow-same-origin allow-presentation' allowfullscreen='true' allowtransparency='true' frameborder='0' height='315' src='https://www.mentimeter.com/embed/b4b94ecdca22f1610766f0eac9f78a23/a6e79818b9a1' style='position: absolute; top: 0; left: 0; width: 100%; height: 100%;' width='420'&gt;&lt;/iframe&gt;&lt;/div&gt;

## Purpose &amp; Data
- The paired sample `\(t\)`-test is used when we want to test the difference in mean scores for a sample measured at two points in time. 
  - Thus this is a first example of a repeated measures design.
- Data Requirements
  - A continuously measured variable.
  - A binary variable denoting time.

## Example
- I want to assess whether a time-management course helps reduce exam stress in students. 
- I ask 50 students to take a self-report stress measure during their winter exams. 
- At the beginning of semester 2 they take a time management course. 
- I then assess their self-report stress in the summer exam block.
	- Let's assume for the sake of this example that I have been able to control the volume and difficulty of the exams the students take in each block.

## Data



```
## # A tibble: 6 x 3
##   ID    stress time 
##   &lt;chr&gt;  &lt;dbl&gt; &lt;fct&gt;
## 1 ID1       14 t1   
## 2 ID2        7 t1   
## 3 ID3        8 t1   
## 4 ID4        8 t1   
## 5 ID5        7 t1   
## 6 ID6        7 t1
```

## Calculating difference
- In the paired `\(t\)`-test, we specifically calculate and analyse the difference in scores at time 1 and time 2 per participant.

$$
d_i = x_{i1} - x_{i2}
$$

## Test statistic
- The resulting test statistic:

$$
t = \frac{\bar{d}}{s_{d} / \sqrt{n}}
$$

- where:
  - `\(\bar{d}\)` = mean of the individual difference scores ($d_i$)
  - `\(s_{d}\)` = standard deviation of the difference scores ($d_i$)
  - `\(n\)` = sample size
- The associated sampling distribution is a `\(t\)`-distributon with `\(n-1\)` degrees of freedom.
  - Note, this is just essentially a one sample test on the difference scores.
  
## Hypotheses
- Two-tailed:

$$
`\begin{matrix}
H_0: \mu_{d} = 0 \\
H_1: \mu_{d} \neq 0
\end{matrix}`
$$

- One-tailed

$$
`\begin{matrix}
H_1: \mu_{d} &lt; 0 \\
H_1: \mu_{d} &gt; 0
\end{matrix}`
$$

## Our Example
- I elect to use a two-tailed test with alpha of .01
- I want to be quite sure the intervention has worked and stress levels have changed.
- So my hypotheses are:

$$
`\begin{matrix}
H_0: \mu_{d} = 0 \\
H_1: \mu_{d} \neq 0
\end{matrix}`
$$

## Calculation
- Steps in my calculations:
  - Calculate the difference scores for individuals.
  - Calculate the mean of the difference scores.
  - Calculate the SD of the difference scores.
  - Check I know my N.
  - Calculate the standard error of the mean difference.
  - Use all this to calculate `\(t\)`
  - Calculate my degrees of freedom

## Data organisation
- Our data is currently in what is referred to as long format.
  - All the scores are in one column, with two entries per participant.
- To calcuate the `\(d_i\)` values, we will convert this to wide format.
  - Where there are two columns representing the score at time 1 and time 2
  - And a single row per person
  
## Data organisation

```r
exam_wide &lt;- exam %&gt;%
  pivot_wider(id = ID, 
              names_from = time, 
              values_from = stress)
```


```
## # A tibble: 6 x 3
##   ID       t1    t2
##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 ID1      14     7
## 2 ID2       7     7
## 3 ID3       8     9
## 4 ID4       8    12
## 5 ID5       7    10
## 6 ID6       7     9
```

## Calculation

```r
calc &lt;- exam_wide %&gt;%  
  mutate(
    dif = t1 - t2) %&gt;%
  
  summarise(
    D = mean(dif),
    SDd = round(sd(dif),2),
    N = n()) %&gt;%
  
  mutate(
    SEd = round(SDd /sqrt(N),2),
    t = round(D/SEd,2)
  ) 
```


```
## # A tibble: 1 x 5
##       D   SDd     N   SEd     t
##   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   2.1  3.55    50   0.5   4.2
```

## Is my test significant?
- So we have all the pieces we need:
	- `\(t\)` = 4.2 
	- `\(df\)` = `\(n-1\)` = 49
	- Hypothesis to test (two-tailed)
	- `\(\alpha = 0.01\)`
- So now all we need is the critical value from the associated `\(t\)`-distribution in order to make our decision .

## Is my test significant?
![](lec16_onesamplet_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;


```r
tibble(
  LowerCrit = round(qt(0.005, 49),2),
  UpperCrit = round(qt(0.995, 49),2),
  Exactp = round(2*(1-pt(calc[[5]], 49)),5)
)
```

```
## # A tibble: 1 x 3
##   LowerCrit UpperCrit  Exactp
##       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1     -2.68      2.68 0.00011
```

## In R

```r
res &lt;- t.test(exam_wide$t1, exam_wide$t2, 
       paired = TRUE, 
       alternative = "two.sided")
```


```
## 
## 	Paired t-test
## 
## data:  exam_wide$t1 and exam_wide$t2
## t = 4.1864, df = 49, p-value = 0.0001174
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.091937 3.108063
## sample estimates:
## mean of the differences 
##                     2.1
```

- Again, slight rounding differences.

## Assumptions
1. Normality of the difference scores ($d_i$)
2. Independence of observations **within** group/time
3. Data are matched pairs (design)

## Write-up
A paired-sample `\(t\)`-test was conducted in order to determine a if a statistically significant ($\alpha$ = .01) mean difference in self-report stress was present, pre- and post-time management intervention in a sample of 50 undergraduate students. The pre-intervention mean score was higher (Mean=9.72) than the post intervention score (Mean = 7.62). The difference was statistically significant ($t$(49)= 4.19, `\(p\)` &lt; . 01, two-tailed). Thus, we reject the null hypothesis of no difference.

## Effect Size: Cohen's D
- Cohen's-$D$ is the standardized difference in means.
- The basic form of `\(D\)` is the same across the different `\(t\)`-tests:

##  Cohen's D: One-sample t
- One-sample t-test:
$$
D = \frac{\bar{x} - \mu}{s}
$$

- `\(\mu\)` = population mean
-	`\(\bar{x}\)` = sample mean
-	`\(s\)` = sample standard deviation

##  Cohen's D: Independent t 
- Independent-sample t-test:

$$
D = \frac{\bar{x}_1 - \bar{x}_2}{s_p}
$$

- `\(\bar{x}_1\)` = mean group 1
-	`\(\bar{x}_2\)` = mean group 2
-	`\(s_p\)` = pooled standard deviation

##  Cohen's D: Paired t
- Paired-sample t-test:

$$
D = \frac{\bar{d} - 0}{s_{d}}
$$

- `\(\bar{d}\)` = mean of the difference scores ($d_i$)
- `\(s_{d}\)` = standard deviation of the difference scores ($d_i$)

## Interpreting Cohen's D
- Very crude interpretations of *D* -scores:
	- ~ 0.2 = small effect
	- ~ 0.5 = moderate effect
	- ~ 0.8 = large effect

##  Summary: Three different t-tests 

&lt;table class="table" style="font-size: 18px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; One-sample &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Independent Sample &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Paired (Dependent) Sample &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Outcome &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Continuous Variable &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Continuous Variable &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Continuous Variable &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Predictor &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Single group vs population &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Categorical: two groups &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Categorical: two time points &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Sample &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; One sample vs population value &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Two independent groups &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; One group sampled at two time points &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Measure of difference &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Observed - known population value &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Group 1 - Group 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Time 1 - Time 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Measure of Variability &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Standard error of the mean &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Pooled standard error of difference in means &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Standard error of the difference in means &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


---

# Tasks for this week...
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
