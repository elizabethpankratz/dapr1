<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Hypothesis testing: p-values</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Umberto Noè" />
    <script src="jk_libs/libs/header-attrs/header-attrs.js"></script>
    <link href="jk_libs/libs/panelset/panelset.css" rel="stylesheet" />
    <script src="jk_libs/libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="un-xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="jk_libs/tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b>Hypothesis testing: p-values</b>
]
.subtitle[
## <small>Data Analysis for Psychology in R 1<br>Semester 2, Week 2</small>
]
.author[
### <b>Dr Umberto Noè</b>
]
.institute[
### Department of Psychology<br/>The University of Edinburgh
]

---













# Learning objectives

1. Understand null and alternative hypotheses, and how to specify them for a given research question.

1. Understand the concept of and how to obtain a null distribution.

1. Understand statistical significance and how to calculate p-values from null distributions.



---
class: inverse, center, middle

---
class: inverse, center, middle

# Part A
## Introduction


---
# Setting

- We cannot afford to collect data for the full population due to time and/or budget constraints

- Data collected for a random sample of size `\(n\)`

- We are interested in the population mean `\(\mu\)`, but this is unknown as we cannot compute it

- Last week we learned how to:

    + obtain an estimate for the population mean
    + obtain a measure of precision of our estimate
    + report the estimate along with the precision
    + compute and report a range of plausible values for the population mean, called __confidence interval__


---
# Where are we going?

- Are children exposed to pesticides more likely to develop ADHD (attention-deficit/hyperactivity disorder) that those who aren't? 
    
    &lt;!-- + Is `\(p_{\text{exposed}} &gt; p_{\text{not exposed}}? \qquad\)` where `\(p\)` is the proportion of all children diagnosed with ADHD. (Population proportion = `\(p\)` = parameter. Sample proportion = `\(\hat p\)` = estimate). --&gt;

--

- Do students who eat breakfast achieve more than students who do not eat breakfast?
    
    &lt;!-- + Is `\(\mu_{\text{breakfast}} &gt; \mu_{\text{no breakfast}}? \qquad\)` where `\(\mu\)` is the mean achievement score. --&gt;

--

- Is the audience appreciation of shows appearing on Broadway lower than the audience appreciation of the touring version of the same show?
    
    &lt;!-- + Is `\(\mu_{\text{Broadway}} &lt; \mu_{\text{Touring}}? \qquad\)` where `\(\mu\)` is the mean audience appreciation score. --&gt;

--

- If you want to remember something, should you take a nap or have some caffeine?
    
    &lt;!-- + Is `\(\mu_{\text{nap}} \neq \mu_{\text{coffee}}? \qquad\)` where `\(\mu\)` is the mean recall. --&gt;


---
# Where are we going?

- What do all of the previous questions have in common?  

--

- Testing a claim about a population parameter!


---
# Where are we going?

- Are children exposed to pesticides more likely to develop ADHD (attention-deficit/hyperactivity disorder) that those who aren't? 
    
    + Is `\(p_{\text{exposed}} &gt; p_{\text{not exposed}}? \qquad\)` where `\(p\)` is the proportion of all children diagnosed with ADHD. (Population proportion = `\(p\)` = parameter. Sample proportion = `\(\hat p\)` = estimate).

--

- Do students who eat breakfast achieve more than students who do not eat breakfast?
    
    + Is `\(\mu_{\text{breakfast}} &gt; \mu_{\text{no breakfast}}? \qquad\)` where `\(\mu\)` is the mean achievement score.

--

- Is the audience appreciation of shows appearing on Broadway lower than the audience appreciation of the touring version of the same show?
    
    + Is `\(\mu_{\text{Broadway}} &lt; \mu_{\text{Touring}}? \qquad\)` where `\(\mu\)` is the mean audience appreciation score.

--

- If you want to remember something, should you take a nap or have some caffeine?
    
    + Is `\(\mu_{\text{nap}} \neq \mu_{\text{coffee}}? \qquad\)` where `\(\mu\)` is the mean recall.


---
# Where are we going?

- Many research hypotheses involve testing a claim about a population parameter. 

--

- We will look at a widely applicable method (called __hypothesis test__ or __test of significance__) that allows you to test an hypothesis about a population parameter. 

--

- This method will allow you to answer many types of questions you may have about a population. All you have to do is 

    + collect relevant sample data
    + perform a hypothesis test
    + report it correctly

--

- If you have a research question you are interested in, and you perform the steps above correctly, you may end up writing up your research results in your first journal paper after that!




---
# Lecture example: Body temperature

- Today's recurring example will focus on answering the following research question:

&gt; Has the average body temperature for healthy humans changed from the long-thought 37 °C? 

--

- We will use data comprising measurements on body temperature and pulse rate for a sample of `\(n = 50\)` healthy subjects. Data link: https://uoepsy.github.io/data/BodyTemperatures.csv

--



```r
library(tidyverse)
tempsample &lt;- read_csv('https://uoepsy.github.io/data/BodyTemperatures.csv')
glimpse(tempsample)
```

```
## Rows: 50
## Columns: 2
## $ BodyTemp &lt;dbl&gt; 36.44, 37.44, 37.22, 37.11, 36.67, 37.17, 37.22, 36.56, 36.00…
## $ Pulse    &lt;dbl&gt; 69, 77, 75, 84, 71, 76, 81, 77, 75, 81, NA, 78, 71, 80, 70, 7…
```

```r
tempsample &lt;- tempsample %&gt;% drop_na(BodyTemp)
dim(tempsample)
```

```
## [1] 50  2
```

---
# Lecture example: Body temperature


```r
# both n. rows and n. cols
dim(tempsample)
```

```
## [1] 50  2
```

```r
# n. rows only
n &lt;- nrow(tempsample)
n
```

```
## [1] 50
```

```r
# sample mean
xbar &lt;- mean(tempsample$BodyTemp)
xbar
```

```
## [1] 36.81
```

- The sample mean is `\(\bar x\)` = 36.81 °C

---
class: inverse, center, middle

---
class: inverse, center, middle

# Part B
## Hypotheses and null distribution


---
# Two hypotheses

- Let's start with an analogy from law. Consider a person who has been indicted for committing a crime and is being tried in a court. 

--

- Based on the available evidence, the judge or jury will make one of two possible decisions:

    1. The person is not guilty.
    2. The person is guilty.

--

- Due to the principle of __presumption of innocence__, at the outset of the trial, the person is presumed not guilty. 

    - "The person is not guilty" corresponds to what is called in statistics the __null hypothesis__, denoted `\(H_0\)`.

--

- The prosecutor's job is to prove that the person has committed the crime and, hence, is guilty.

    - "The person is guilty" corresponds to what is called in statistics the __alternative hypothesis__, denoted `\(H_1\)`.

--

- The evidence that the prosecutor needs to provide must be __beyond reasonable doubt__.


---
# Two hypotheses

- In the beginning of the trial it is assumed that the person is not guilty.

--

- The null hypothesis `\(H_0\)` is usually the hypothesis that is assumed to be true to begin with. It typically corresponds to "no change", "no effect", "no difference", "no relationship". 

    + It involves the equality symbol `\((=)\)`

    - The null hypothesis usually is the skeptical claim that nothing is different / nothing is happening.

    + Are we considering a (New! Improved!) possibly better method? The null hypothesis says, "Really? Convince me!" To convert a skeptic, we must pile up enough evidence against the null hypothesis that we can reasonably reject it.

--

- The alternative hypothesis is the claim that we wish to find evidence for. It is typically the hypothesis that embodies the research question of interest.

    + It involves the less than `\((&lt;)\)` or greater than `\((&gt;)\)` or not equal to `\((\neq)\)` symbols
    + If `\(H_1\)` uses the symbol `\(&lt;\)`, the test is called left-tailed or left-sided
    + If `\(H_1\)` uses the symbol `\(&gt;\)`, the test is called right-tailed or right-sided
    + If `\(H_1\)` uses the symbol `\(\neq\)`, the test is called two-tailed or two-sided


---
# Test of significance

- A __hypothesis test__ (or __test of significance__) is a procedure for testing a claim about a population parameter (i.e. a property of a population).

--

- The test works by weighting the evidence __against__ the null (and in favour of the alternative).

    + We want to be sure the sample data provide enough evidence against `\(H_0\)` before rejecting it in favour of `\(H_1\)`.

--

- The evidence in statistics corresponds to the sample statistic (numerical summary of the sample data). 

    + Informally, people say that the evidence corresponds to the sample data.

--

- The evidence provided must be __beyond reasonable doubt__. 

    + If `\(H_0\)` is true, it should be very unlikely for a random sample to give that value of the statistic.  
    If a person is innocent, it should be very unlikely to pile up so much evidence against innocence.
    
    + If it were very likely for a random sample to give that value of the sample statistic, then what we observed could just be a fluke due to random sampling rather than due to `\(H_1\)`.


---
# Lecture example: Body temperature

&gt; Has the average body temperature for healthy humans changed from the long-thought 37 °C? 

- State the hypotheses using proper symbols for the population parameters. 

`$$H_0: \mu = 37$$`
`$$H_1: \mu \neq 37$$`

--

- From the sample data we can compute the sample mean, which is our estimate of `\(\mu\)`


```r
xbar &lt;- mean(tempsample$BodyTemp)
xbar
```

```
## [1] 36.81
```

--

- `\(\overline x = 36.81\)` °C, which differs from 37 °C

--

- Is this difference large enough to be really due to a systematic shift in the average body temperature of healthy humans?

--

- Or perhaps the population mean is truly = 37 °C, and the difference between 36.81 °C and 37 °C is simply due to random sampling?


---
# Recap

&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-4-1.png" width="50%" style="display: block; margin: auto;" /&gt;


---
# Null distribution

- The sample mean varies from sample to sample, and all the possible values along with their probabilities form the sampling distribution:
`$$\overline X \sim N(\mu, \frac{\sigma}{\sqrt n})$$`

--

- If the population mean `\(\mu\)` was truly equal to 37, as the null hypothesis says, how would the sample means look?

--

- If `\(H_0: \mu = 37\)` is true, the sample mean would follow the distribution:
`$$\overline X \sim N(37, \frac{\sigma}{\sqrt n})$$`

--

- We can standardise it to obtain a distribution with mean = 0 and SD = 1 (__z-score__):
$$
Z = \frac{\overline X - 37}{\frac{\sigma}{\sqrt n}} \sim N(0, 1)
$$


---
# Null distribution

- __However__, we cannot compute the population SD `\(\sigma\)` too...

--

- Estimate it with sample SD, denoted `\(s\)`. The distribution however becomes a `\(t(n-1)\)`

--

- When you standardise the sample mean using `\(SE_{\bar{x}} = s / \sqrt{n}\)`, you have the __t-statistic__:
$$
\underbrace{t = \frac{\overline X - 37}{\frac{s}{\sqrt n}}}_{\textbf{t-statistic}} \sim t(n-1)
$$

--

- The t-statistic is sometimes called the __t-score__ (or t-scored sample mean, same thing)

--

- The distribution of the t-statistic, __assuming the null hypothesis to be true__, is called the __null distribution__. 

    + It tells us which values of the t-statistic we would expect to see if `\(H_0\)` were true.



---
class: inverse, center, middle

---
class: inverse, center, middle

# Part C
## t-statistic and p-value

---
# The t-statistic

- For `\(H_0 : \mu = \mu_0\)` the t-statistic is:

`$$t = \frac{\overline x - \mu_0}{\frac{s}{\sqrt n}} = \frac{\text{difference between sample and hypothesised mean}}{\text{variation in sample means due to random sampling}}$$`

--

- The __t-statistic__ measures how many standard errors away from `\(\mu_0\)` is our sample mean `\(\overline x\)`.

--

- It compares the difference between the sample and hypothesised mean, to the expected variation in the means due to random sampling.

--

- __Note__: The terms __t-score__, __t-statistic__ and __t-value__ are used as synonyms

--

- When referring to the t-statistic computed on the observed sample, people often say:

    + the observed value of the t-statistic 
    + the observed t-value


---
# Visually

.pull-left[
&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
Consider `\(H_0 : \mu = \mu_0\)`

`$$t = 0 
\quad \text{when} \quad
\dfrac{\overline x - \mu_0}{\frac{s}{\sqrt n}} = 0 
\quad \text{when} \quad
\bar x = \mu_0$$`

Roughly speaking:

- We are very likely to see a t-score between -2 and 2 if in the population the mean is really `\(\mu_0\)` (37 in the Body Temperature example)

- We are very unlikely to see a t-score smaller than -2 or larger than 2 if in the population mean is really `\(\mu_0\)` (37 in the Body Temperature example)

]


---
# Visually

.pull-left[
&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
- If our random sample leads to an observed t-value that has relatively high probability in the null distribution

    + There are many random samples leading to the same t-value when `\(H_0\)` is true
    
    + Hence, it is very likely to obtain such t-value just from random sampling.
]


---
# Visually

.pull-left[
&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
- If our sample leads to an observed t-value that has relatively low probability, 

    + there are very few random samples leading to the same t-value when `\(H_0\)` is true.
    
    + The observed t-value is __unlikely__ to be obtained from random samples when `\(H_0\)` is true. That surprisingly high or low t-value may be due to something else (our claim).
]


---
# Evaluating how unlikely

- We need an objective criterion to evaluating how unlikely it is to see the observed t-value if `\(H_0\)` is true.

- Just plotting a line on a graph can lead to very different conclusions based on the reader's perception of probability and their risk-aversion.


---
# p-value

- In statistics, the evidence against the null hypothesis is provided by data (and not the prosecutor) and we use a probability to say how strong the evidence is.

--

- The probability that measures the strength of the evidence against a null hypothesis is called a __p-value__.

--

&gt; __Definition__  
&gt; The p-value is the probability, computed assuming that `\(H_0\)` is true, of obtaining a t-value __at least as extreme as that observed__.

--

- Operationally, extreme corresponds to the direction specified by `\(H_1\)`. 

    + If &gt;, find the probability of larger t-scores than that observed
    + If &lt; find the probability of smaller t-scores than that observed
    + If `\(\neq\)` use both tails


---
# Visually: p-value

- If `\(H_1 : \mu &gt; \mu_0\)` and `\(t = 1.3\)`, __p-value = B__

&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# Visually: p-value

- If `\(H_1 : \mu &lt; \mu_0\)` and `\(t = 1.3\)`, __p-value = A__

&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-9-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---
# Visually: p-value

- If `\(H_1 : \mu \neq \mu_0\)` and `\(t = 1.3\)`, __p-value = A + C__

&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# Body temperature example

- We have that `\(\bar x = 36.81\)` °C. Let's compute the t-statistic, telling us how many SEs away from 37 °C the value 36.81 °C is.


```r
xbar &lt;- mean(tempsample$BodyTemp)
s &lt;- sd(tempsample$BodyTemp)
n &lt;- nrow(tempsample)
SE &lt;- s / sqrt(n)

mu0 &lt;- 37  # null hypothesis value

tvalue &lt;- (xbar - mu0) / SE
tvalue
```

```
## [1] -3.141
```


The value of the t-statistic from the observed sample is
`$$t = -3.141$$`

---
# Body temperature example

- Our alternative is `\(H_1 : \mu \neq 37\)`, so something is very different from that value either if it's (a) much bigger or (b) much smaller. 

--

- The observed t-value is `\(t = -3.141\)`, so we compute the p-value as `\(P(T \leq -3.141) + P(T \geq +3.141)\)`

--

- If you drop the negative sign by using the absolute value `\(|t| = |-3.141| = 3.141\)`, you can write this as `\(P(T \leq -|t|) + P(T \geq +|t|)\)`. 

--

- However, the t-distribution is symmetric, so those two probabilities will be the same. 

--

- You can also compute it as `\(2 \cdot P(T \geq |t|)\)`.

--

- In R, the absolute value function is `abs()`


---
# Body temperature example


```r
tvalue
```

```
## [1] -3.141
```

```r
pvalue &lt;- pt(-3.141, df = n-1) + 
          pt(+3.141, df = n-1, lower.tail = FALSE)
pvalue
```

```
## [1] 0.002854
```

```r
pvalue &lt;- pt(-3.141, df = n-1) + 
          (1 - pt(+3.141, df = n-1))
pvalue
```

```
## [1] 0.002854
```

```r
pvalue &lt;- 2 * pt(abs(tvalue), df = n-1, lower.tail = FALSE)
pvalue
```

```
## [1] 0.002851
```


---
# Body temperature example

- We computed the probability of obtaining a t-score at least as extreme as the observed one when `\(H_0\)` is true.

- The p-value is: `\(p = .003\)`




---
# p-value

- The smaller the p-value, the stronger the evidence that the data provide against `\(H_0\)`.

--

- Small p-values are evidence against `\(H_0\)`, because they say that the observed result would be unlikely to occur if `\(H_0\)` was true.

--

- Large p-values fail to provide sufficient evidence against `\(H_0\)` 

--

- However, we need operational definition for _how small_ a p-value should be to provide sufficient evidence against `\(H_0\)`. How small is small?


---
class: inverse, center, middle

---
class: inverse, center, middle

# Part D
## Significance level

---
# Significance level

- We can compare a p-value with some fixed value (called __significance level__ and denoted `\(\alpha\)`) that is in common use as standard for evidence against `\(H_0\)`. 

- The most common fixed values are `\(\alpha = 0.10\)`, `\(\alpha = 0.05\)`, and `\(\alpha = 0.01\)`. 

- The value is chosen by the researcher (__you!__) once for all at the beginning of your study.

- It is important to clearly state the significance level at the start  of your write-ups in every report or journal paper.

- If `\(p \leq 0.05\)`, there is no more than 1 chance in 20 that a sample would give evidence at least this strong just by chance when `\(H_0\)` is actually true. 

- If `\(p \leq 0.01\)`, we have a result that in the long run would happen no more than once per 100 samples when `\(H_0\)` is true. 


---
# Visually: `\(\alpha = 0.05\)`

&lt;img src="dapr1_2_02_ht_pvalues_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---
# Statistical significance: interpretation

- If the p-value `\(\leq \alpha\)`, we say that the data are statistically significant at level `\(\alpha\)`, and we reject `\(H_0\)` in favour of `\(H_1\)`.

    + We say that the sample data provide significant evidence against `\(H_0\)` and in favour of `\(H_1\)`.

--

- If the p-value `\(&gt; \alpha\)`, we say that the data are __not__ statistically significant at level `\(\alpha\)`, and we do not reject `\(H_0\)`.

    + We say that the sample data do not provide sufficient evidence against `\(H_0\)`.

--

- "Significant" is a technical term in scientific research and it doesn't have the same meaning as in everyday English language. 

    + It does __not__ mean "important".  
    
    + It means "not likely to happen just by chance because of random variations from sample to sample".


---
# Guidelines for reporting strenght of evidence

The following table summarizes in words the strength of evidence that the sample results bring in favour of the alternative hypothesis for different p-values:

| Approximate size of p-value  | Loose interpretation                   |
|:----------------------------:|:---------------------------------------|
| p-value `\(&gt;\)` 0.1              | little or no evidence against `\(H_0\)`    |
| 0.05 `\(&lt;\)` p-value `\(\leq\)` 0.1  | some evidence against `\(H_0\)`            |
| 0.01 `\(&lt;\)` p-value `\(\leq\)` 0.05 | strong evidence against `\(H_0\)`          |
| p-value `\(\leq\)` 0.01          | very strong evidence against `\(H_0\)`     |


---
# Reporting

- It is important to always report your conclusions in full, without hiding information to the reader.

- Restate your decision on whether you reject or fail to reject `\(H_0\)` in simple nontechnical terms, making sure to address the original claim, and provide the reader with a take-home message.

- Report test as follows: t(`df`) = `tvalue`, p = `pvalue`, `one/two`-sided.

    + t(49) = -3.14, p = .003, two-sided

- According to APA style, __don't__ include the zero before the decimal place for p-values.

- Irrespectively of your `\(\alpha\)` level, if your p-value is `\(\geq\)` .001 it is good practice to report it __in full__ but using proper rounding.

- Irrespectively of your `\(\alpha\)` level, if your p-value is &lt; .001 you can just  report it as p &lt; .001 as people don't really care about 5th or 6th decimal numbers.


---
# Body temperature example

At the `\(\alpha = 0.05\)` significance level, we performed a two-sided hypothesis test against the null hypothesis that the mean body temperature for all healthy humans is equal to 37 °C.  
The sample results provide very strong evidence against the null hypothesis and in favour of the alternative one that the average body temperature differs from 37 °C; `\(t(49) = -3.14, p = .003\)`, two-sided.



---
# Note

- Failing to find sufficient evidence against `\(H_0\)` means only that the data are __consistent__ with `\(H_0\)`, not that we have proven `\(H_0\)` to be true.

- Example: not finding sufficient evidence that person is guilty doesn't necessarily prove they are innocent. They could have just hidden every single possible trace.

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="jk_libs/macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
