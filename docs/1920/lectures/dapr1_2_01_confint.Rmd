---
title: "<b>Confidence Intervals</b>"
subtitle: "<small>Data Analysis for Psychology in R 1<br>Semester 2, Week 1</small>"
author: "<b>Dr Umberto Noè</b>"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: jk_libs/libs
    css: 
      - un-xaringan-themer.css
      - jk_libs/tweaks.css
    nature:
      beforeInit: "jk_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)

theme_set(
  theme_classic(base_size = 18) +
    theme(plot.title = element_text(hjust = 0.5))
)

options(htmltools.dir.version = FALSE)
options(digits=4, scipen=2)
options(knitr.table.format="html")

knitr::opts_chunk$set(
  dev = "png",
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  # cache = TRUE,
  fig.align = 'center',
  fig.height = 5, fig.width = 6,
  out.width = "80%",
  dpi = 300
)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  outfile = "un-xaringan-themer.css"
)
```


```{r preamble, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(patchwork)
```


# Learning objectives

1. Understand the importance of a confidence interval.

1. Understand the link between standard errors and confidence intervals.

1. Understand how to construct a confidence interval for an unknown parameter of interest.



---
class: inverse, center, middle

# Part A
## Recap


---
# Normal distribution

.pull-left[
$X \sim N(\mu, \sigma)$

Probability to the LEFT of a value `x`:

```
p <- pnorm(x, mean = mu, sd = sigma)
```

Value `x` having a probability of `p` to its LEFT:

```
x <- qnorm(p, mean = mu, sd = sigma)
```

Example with $N(0,1)$:

```{r, echo=T}
qnorm(0.975)
pnorm(1.96)
```
]


.pull-right[
```{r}
#| out.width = "100%"
xx <- seq(-3, 3, 0.01)
yy <- dnorm(xx)
plot(xx, yy, frame.plot = F, axes = F, type = 'l',
      xlab = expression(mu), cex.lab = 2, ylab = '', lwd = 2,
      col = 'red')
abline(v = 0, col = 'gray', lty = 2, lwd = 2)
arrows(0, 0.01, 1, 0.01, code = 3, lwd = 2, col = 'gray')
text(0.5, 0.04, labels = expression(sigma), cex = 2)
```
]

???

- A variable $X$ follows a normal distribution with mean $\mu$ and standard deviation $\sigma$ if its distribution is bell-shaped and symmetric. We write is as $X \sim N(\mu, \sigma)$


---
# Standardisation / z-scoring

- Let $X \sim N(\mu, \sigma)$

--

- Define:
$$
Z = \frac{X - \mu}{\sigma}
$$

--

- $Z \sim N(0,1)$ follows a standard normal distribution

--

- To transform $Z$ into $X$ we use this transformation:
$$
X = \mu + Z \cdot \sigma
$$

---
# Normal 68–95–99.7 rule

- Recall that for a random variable $X \sim N(\mu, \sigma)$, roughly 95% of the values fall between $\mu - 2 \sigma$ and $\mu + 2 \sigma$:

```{r}
knitr::include_graphics('images/2_01_confint/normal_rule.png')
```

---
# Normal 68–95–99.7 rule

- The interval below contains __roughly__ 95% of the values in the distribution:
$$
\left[ 
\mu - 2 \cdot \sigma , \
\mu + 2 \cdot \sigma
\right]
$$

--

- To be more accurate, we need to find the x-values (quantiles) that have 0.025 probability to the left and 0.025 probability to the right, leaving 0.95 probability in the middle.

```{r echo=T}
qnorm(c(0.025, 0.975))  # using a N(0,1) distribution
```

--

- The values $-1.96$ and $1.96$ are the quantiles of a standard Normal distribution, cutting a probability of 0.025 in the tails each.

$$
\begin{aligned}
z = -1.96 & \quad \rightarrow \quad x = \mu - 1.96 \cdot \sigma \\
z = 1.96 &\quad \rightarrow \quad x = \mu + 1.96 \cdot \sigma
\end{aligned}
$$

--

- The correct interval comprising exactly 95% of the values is:

$$
\left[ 
\mu - 1.96 \cdot \sigma , \
\mu + 1.96 \cdot \sigma
\right]
$$


???

- If we want to have 0.95 prob in the middle, we must have 0.05 prob equally divided in the tails, that is 0.025 on each tail.

- qnorm wants the prob to the left, so the for the first quantile we put 0.025 and the second 1-0.025 = 0.975

---
# Using statistics to estimate parameters

- Without loss of generality, in this lecture we will focus on the mean as the numerical summary of data.

    + Population mean $\rightarrow$ 
    unknown $\rightarrow$ 
    example of a parameter $\rightarrow$ $\mu$
    
    + Sample mean $\rightarrow$ 
    we can compute it $\rightarrow$ 
    example of a statistic $\rightarrow$ $\bar x$

--

- We are typically interested in __estimating an unknown population mean__ (a __parameter__, $\mu$) using the __mean computed on a random sample__ (a __statistic__, $\bar x$).

--

- We will also call the sample mean (= statistic) the __estimate__.

--

- FACT: statistics vary from sample to sample and have a __sampling distribution__.

--

- The standard deviation of the sampling distribution is called the __standard error__ (SE)

  + SE tells us the size of the typical "estimation error" = $\bar x - \mu$.
  
  + $SE = \dfrac{\sigma}{\sqrt{n}}$



---

# Key question

> How accurate is our estimate?

- We are interested in how accurate our statistic $\bar{x}$ is as an estimate of the unknown parameter $\mu$.

--

- Accuracy is a combination of two things:

  + No bias
  + Precision

--

- We avoid bias if we use random sampling. We have bias if our samples systematically do not include a part of the population.
  
  + If you choose convenience samples, you will systematically over-estimate or under-estimate the true value. 

--

- Precision relates to the variability of the sampling distribution, and the Standard Error (SE) is used to quantify precision.
    
    - SE = sd(of sampling distribution)
    
    - The smaller the SE, the closer our sample mean will tend to be to the population mean


???

- We want to report our reader not only an estimate of the unknown parameter, but also a measure of precision of our estimate. In other words, how reliable is it?

- We aim for a statistic to be precise and not biased.

- The sampling distribution of the statistic is used to assess precision.



BIAS

- Bias is avoided if you select samples at random from the population. You have bias if your samples systematically do not include a part of the population.

- Bias is related to the centre of the sampling distribution, and you have bias when the statistics on average tend to be systematically “off” from the true value, meaning that we don’t have good guesses of the true parameter.

- Example: True IQ is 100, but the average of the statistics is 120. We are very off, we may not have captured specific parts of the population in our samples.

- Example: you want to estimate the average study hours per day of students in your university. If you select 50 students only from the library, your estimate will be higher than the true value. This is because your sample is not a good representation of the population, some students are not well-represented in the sample.


PRECISION

- The lower the SE, the lower is the typical “estimation error”, and hence the higher is the precision. If the SE is high, the precision is low, and this means that we don’t have reliable estimates as they vary too much from one sample to another.

- Example 1: One sample gives an estimate of 70, another sample of 115. They are very different, which one do we trust? Would you trust 70 to be a good guess? And 115?

- Example 2: One sample gives an estimate of 95, another sample of 101. Do you trust the values more now?


---
# Bias vs Precision

```{r}
knitr::include_graphics('images/2_01_confint/bias_prec.png')
```

---
# Sampling distribution

```{r}
knitr::include_graphics('images/2_01_confint/2_01_sampl_dist.png')
```


---
# Sampling distribution

```{r}
knitr::include_graphics('images/2_01_confint/2_01_sampl_dist_t.png')
```

---
# Sampling distribution

```{r}
knitr::include_graphics('images/2_01_confint/2_01_sampl_dist_t_2.png')
```


---
class: inverse, center, middle


---
class: inverse, center, middle

# Part B
## One sample only


---
# One sample only

```{r}
knitr::include_graphics('images/2_01_confint/2_01_one_sample.png')
```


---
# One sample only: Precision of sample mean

- If we do NOT have the population data:

    - we cannot compute $\mu$, the population mean
    
    - we also cannot compute $\sigma$, the population standard deviation

--

- Recall that $\sigma$ is required to assess the precision of the sample mean by computing the SE:

$$
SE = \frac{\sigma}{\sqrt n}
$$

--

- How can we compute the SE of the mean if we __do not have data on the full population__, and we __can only afford one sample__ of size $n$?


---
# One sample only: Precision of sample mean

- We must also estimate $\sigma$ with the corresponding sample statistic.

- Substitute $\sigma$ with the standard deviation computed in the sample, $s$.

- Standard error of the mean becomes:

$$
SE = \frac{s}{\sqrt n}
$$

- Report estimate (sample mean), along with a measure of its precision (the above SE).


---
class: inverse, center, middle



---
class: inverse, center, middle

# Part C
## Confidence Intervals


---
# Key idea

- Parameter estimate = single number. Almost surely the true value will be different from our estimate.

--

- Range of plausible values for the parameter, called __confidence interval__. More likely that the true value will be captured by a range.

--

```{r}
knitr::include_graphics('https://d33wubrfki0l68.cloudfront.net/45f6d2e16255dbcb42de86336e1e49ef732aa5da/8bcd0/images/shutterstock/point_estimate_vs_conf_int.png')
```


---
# Confidence interval

- Confidence interval (CI) = range of plausible values for the parameter.

--

- To create a confidence interval we must decide on a confidence level.

--

- Confidence level = a number between 0 and 1 specified by us. How confident do you want to be that the confidence interval will contain the true parameter value?

--

- The larger the confidence level, the wider the confidence interval.

  + How confident are you that I am between 39 and 42 years old?
  
  + How confident are you that I am between 35 and 50 years old?
  
  + How confident are you that I am between 18 and 70 years old?

--

- Typical confidence levels are 90%, 95%, and 99%.


---
# CI for the population mean

- Recall that if $X \sim N(\mu, \sigma)$, 95% of the values are between

$$
\left[ 
\mu - 1.96 \cdot \sigma , \ 
\mu + 1.96 \cdot \sigma
\right]
$$

--

- The sample mean follows a normal distribution:  

$$\bar{X} \sim N(\mu_{\overline{X}},\sigma_{\overline{X}})$$

where
  
  + $\mu_{\overline X} = \mu$  
  
  + $\sigma_{\overline X} = SE = \dfrac{\sigma}{\sqrt n}$

--

- Substitute in the interval above:

$$\left[ 
\mu - 1.96 \cdot \frac{\sigma}{\sqrt n} , \ 
\mu + 1.96 \cdot \frac{\sigma}{\sqrt n}
\right]$$



---
# Estimates of $\mu$ and $\sigma$

- Recall that we do not have the full population data. __We can only afford one sample!__

--

- We don't have the population mean $\mu$ and we estimated it with the sample mean $\bar{x}$
 
--

- However, we also don't have $\sigma$ so we need to estimate it with $s$, the sample standard deviation:

$$
\left[ 
\bar{x} - 1.96 \cdot \frac{s}{\sqrt n} , \ 
\bar{x} + 1.96 \cdot \frac{s}{\sqrt n}
\right]
$$

--

- However, this interval is now __wrong!__

--

- Because we didn't know $\sigma$ and we had to estimate it with $s$, this bring and __extra element of uncertainty__

--

- As we are unsure about the actual value of the population standard deviation, the reference distribution is no longer Normal, but a distribution that is more "uncertain" and places higher probability in the tails of the distribution.

--

- When the population standard deviation is unknown, the sample mean follows a t-distribution.

--

- The quantiles -1.96 and 1.96 refer to the normal distribution, so these are wrong and we need to find the correct ones!


---
# t-distribution

```{r}
#| out.width = '60%'
xx = seq(-4, 4, 0.01)
plot(xx, dnorm(xx), type = 'l', frame.plot=F, xlab = '', ylab = '', lwd = 4)
lines(xx, dt(xx, 2), col = 'red', lwd = 2, lty = 2)
lines(xx, dt(xx, 5), col = 'blue', lwd = 2, lty = 2)
lines(xx, dt(xx, 50), col = 'green', lwd = 2, lty = 2)
legend('topright', lty = c(1, 2, 2, 2),
       col = c('black', 'red', 'blue', 'green'),
       legend = c('Normal', 't(2)', 't(5)', 't(50)'),
       lwd = c(4, 2, 2, 2))
```


---
# t-distribution

- A distribution similar to the standard Normal distribution, also with a zero mean

--

- Depends on a number called __degrees of freedom__ (DF) = sample size - 1. That is, $df = n - 1$.

--

- We write the distribution as:

$$
t(n - 1)
$$
--

- Suppose the sample size is 20. In R:

```{r echo=T}
qt(0.025, df = 19)    # quantile = t-value with 0.025 prob to the LEFT
pt(-2.093, df = 19)   # prob to the LEFT of t = -2.093
```


---
# Finally: the correct confidence interval

- Now we can finally compute the correct confidence interval. 

--

- We need to replace the quantiles with those from the $t(n-1)$ distribution, denote them by $-t^*$ and $+t^*$, and these will be different all the time as they depend on the sample size.

--

- Generic form the of the CI for the mean:

$$\left[ 
\bar{x} - t^* \cdot \frac{s}{\sqrt n} , \ \bar{x} + t^* \cdot \frac{s}{\sqrt n}
\right]$$

--

- Generic form the of the 95% CI for the mean with a sample of size $n = 20$:

```{r echo=T}
qt(c(0.025, 0.975), df = 20 - 1)
```

$$\left[ 
\bar{x} -2.093 \cdot \frac{s}{\sqrt n} , \ \bar{x} + 2.093 \cdot \frac{s}{\sqrt n}
\right]$$


---
# Other confidence levels

- Generic form the of the 99% CI for the mean with a sample of size $n = 20$:

```{r echo=T}
qt(c(0.005, 0.995), df = 20 - 1)
```

$$\left[ 
\bar{x} -2.861 \cdot \frac{s}{\sqrt n} , \ \bar{x} + 2.861 \cdot \frac{s}{\sqrt n}
\right]$$


---
# Example: 95% CI for the pop. mean salary

- Parameter of interest: mean yearly salary of a NFL player in the year 2019, denoted $\mu$.

- Sample of 50 players:

```{r echo=T}
library(tidyverse)
nfl_sample <- read_csv("https://uoepsy.github.io/data/NFLSample2019.csv")
dim(nfl_sample)
head(nfl_sample)
```

---
# Example: 95% CI for the pop. mean salary

.pull-left[
```{r echo=T}
xbar <- mean(nfl_sample$YearlySalary)
xbar

s <- sd(nfl_sample$YearlySalary)
s

n <- nrow(nfl_sample)
n

SE <- s / sqrt(n)
SE
```
]

.pull-right[
```{r echo=T}
qt(c(0.025, 0.975), df = n-1)

xbar - 2.01 * SE
xbar + 2.01 * SE
```
]


---
# Example: 95% CI for the pop. mean salary

- The 95% confidence interval for the mean salary of __all__ NFL players in the year 2019 is [2.13, 4.58] million dollars.

--

- Write this up as:

> We are 95% confident that the average salary of a NFL player in 2019 is between 2.13 and 4.58 million dollars.


---
# Warning!

- If you had 100 random samples and computed a 95% confidence interval from each sample:
  
  + about 95 of those intervals will contain the true parameter value
  + about 5 of those intervals will __not__ contain the true parameter value
  
--

- We speak about __probability__ when we refer to the __collection__ of those 100 confidence intervals.  
That is, the probability the that __collection__ of confidence intervals will contain the true parameter value is 0.95.
  
  + Think of this as

$$
\frac{\text{number of CIs containing }\mu}{100}
$$

--

- We speak of __confidence__ when we refer to just __one__ confidence interval that we have computed.  
Say the 95% CI is [2.5, 5.3] min. We would say: we are 95% confident that the population mean is between 2.5 and 5.3 minutes.
  
  + It is __wrong__ to say that there is a 95% probability that the population mean is between 2.5 and 5.3 minutes.


---
# Warning!

```{r}
#| out.width = "50%"
knitr::include_graphics('images/2_01_confint/int-ci-1.png')
```


---
# Warning!

```{r}
#| out.width = "50%"
knitr::include_graphics('images/2_01_confint/int-ci-2.png')
```


---
class: inverse, center, middle
