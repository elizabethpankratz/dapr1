`r optbegin("Parameters vs statistics", olabel = FALSE, show = params$SHOW_SOLS, toggle = params$TOGGLE)`
We can think of random or unpredictable data as arising in two ways. The first one involves _sampling from a finite population_ and measuring characteristics of the individuals chosen in the sample. An example of this are surveys and polls.
The second approach involves a _random process_ producing observations. An example of this is a production line for which we measure some characteristic of each produced item. Here, the underlying population is conceptual rather than real, and is the one that would be produced if the process was repeated a large number of times.

Both ways lead to a random observation possessing a distribution describing how the observation will vary.
Numerical summaries of that distribution are called _parameters_. Examples are the mean $\mu = E(X)$ of the distribution, the standard deviation $\sigma = SD(X)$, or a population proportion $p$.

If we are sampling the population of Scotland, we might be interested in $\mu$, the mean self-reported happiness level, or $p$, the proportion of vaccinated people.

:::yellow
__Parameters__

A _**parameter**_ is a numerical summary of a _**population**_ or _**distribution**_, for example the average income in the whole population.
:::

In practice, we know very little about the population we are sampling from (or the random process generating our data) and we collect data to find out more about these populations.
Therefore the parameters of interest are _unknown_ quantities that we want to estimate.

Consider again the population proportion of vaccinated people, $p$. If this is the quantity we are interested in, the obvious approach would be to take a sample from that population and use the proportion vaccinated in the sample, $\hat{p}$, as an _estimate_ of $p$.

To estimate the fault proportion $p$ in a light bulb production line, we can take some of the light bulb produced (i.e. a sample) and use the proportion of faulty light bulbs in the sample $\hat p$ as an estimate of the underlying proportion of faulty light bulbs $p$ for the production process.


:::yellow
__Statistic__

A _**statistic**_ is a numerical summary of the _**sample**_.

A (sample) statistic is often used to estimate a (population) parameter.
:::


From the above discussion, you can see that the population parameter and the sample statistic generally have the same name.
However, these are often written with different symbols to convey with just one letter:

1. what *summary* they represent;
2. if it is a *population* quantity or a quantity *computed on a sample*.

The following table summarizes standard notation for some population parameters, typically unknown, and the corresponding estimates computed on a sample.

|Numerical summary  | Population parameter   | Sample statistic         |
|:------------------|:----------------------:|:------------------------:|
|Mean               | $\mu$                  | $\bar{x}$ or $\hat{\mu}$ |
|Standard deviation | $\sigma$               | $s$ or $\hat{\sigma}$    |
|Proportion         | $p$                    | $\hat{p}$                |

Table: Notation for common parameters and statistics.


The Greek letter $\mu$ (mu) represents the population mean (parameter), while $\bar{x}$ (x-bar) or $\hat{\mu}$ (mu-hat) is the mean computed from the sample data (sample statistic).

The Greek letter $\sigma$ (sigma) represents the population standard deviation (parameter), while $s$ or $\hat{\sigma}$ (sigma-hat) is the standard deviation computed from the sample data (sample statistic).

The Getter $p$ represents the population proportion (parameter), while $\hat{p}$ (p-hat) is the proportion computed from the sample data (sample statistic).


<br>

The process of sampling $n$ people from the population is a _random process_. An _outcome_ of this random process is _a sample_ of size $n$. For each sample, we can calculate a statistic (e.g., the mean $\bar x$). 
Hence, a statistic is a numerical summary of a random experiment and for this reason it is a random variable, e.g. the mean denoted $\bar X$.

Throughout the exercises we will use the following notation:

- Uppercase letters refer to random variables

- Lowercase letters refer to observed values

<br>

```{r echo=FALSE, out.width = '95%'}
knitr::include_graphics('images/prob/sampling_cloud.png')
```

<br>

We use uppercase letters when we want to study the effects of sampling variation on a statistic, while we use lowercase letters for observed values.

:::frame
__TERMINOLOGY__

Statisticians often refer to the observed number in the sample as the _**estimate**_ ($\bar x$). 
This is just another way of saying a statistic which used to estimate a population parameter.

They also sometimes call _**estimator**_ the random variable ($\bar X$) which the observed number is a realisation of.
:::
`r optend()`