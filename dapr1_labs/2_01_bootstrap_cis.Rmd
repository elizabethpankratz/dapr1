---
title: "Confidence Intervals & Bootstrapping"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---

```{r setup, include=FALSE}
source('assets/setup.R')

knitr::opts_chunk$set(cache=F, message=F)
```

```{r include=FALSE}
library(tidyverse)
library(patchwork)
```

:::lo
**LEARNING OBJECTIVES**

1. Understand how to construct a confidence interval for an unknown parameter of interest.
1. Understand the link between bootstrap-based standard errors and theory-based standard errors.
1. Understand how bootstrapping can be used to approximate a sampling distribution. 
:::


# Introduction

Without loss of generality, we will consider the sample mean as the statistic of interest and we will consider two scenarios:

- Entire population data available (unlikely);  
- Entire population data are NOT available (more common).

For both scenarios, we will investigate the following question: 

> What was the average yearly salary of a National Football League (NFL) player in 2015?  


## A. Population data available (unlikely)

If we have data on the entire population of NFL players and we are interested in a parameter such as the population mean salary, we can simply compute the mean on the available population data. 
There would be no uncertainty and nothing to estimate: we have the entire population data, so we can compute the mean salary, and we would find what the actual parameter value is.

In this scenario, we would have a file containing the yearly salaries (in millions of dollars) for all players being paid at the start of 2015 by a National Football League (NFL) team. This entire dataset represents the population of all National Football League players in 2015.

The data on the entire population:

```{r}
library(tidyverse)

nfl_pop <- read_csv("https://uoepsy.github.io/data/nflpop.csv")
head(nfl_pop)
```

The population mean salary: 

```{r}
nfl_pop_mean_salary <- mean(nfl_pop$YearlySalary)
nfl_pop_mean_salary
```

Above we actually had the data on the entire population available, meaning that we can actually know the population parameter (the average yearly salary of NFL players in 2015) with no uncertainty. 

Say we wanted to check whether 1 million was a plausible average yearly salary for a NFL player in 2015.  There answer is no, it isn't. We know the actual average salary which is 3.03 millions, and this is different from 1 million.


## NA. Population data NOT available (more common)

Now suppose we didn't know anything from the previous section (Section A).

In most research, the data for the entire population is not available: typically we cannot afford to collect data on the entire population. 
As a consequence, we cannot compute the population parameter, which is **unknown**, and we must rely on random **sampling** to estimate it. It is good practice to use a sample size as large as we can afford.

Let's pretend for now that we don't have the entire NFL population data, and are only able to collect data for 50 players. Fortunately someone else did it for us: they chose 50 players at random and interviewed them to find out their salary. The sample data are:

```{r}
nfl_sample <- read_csv("https://uoepsy.github.io/data/nflsamp.csv")
nfl_sample
```

We estimate the **unknown** population mean salary (what we are interested in) with the sample mean salary, which we can compute from the obtained sample. The sample mean salary represents our "best guess" of the population mean salary.

```{r}
nfl_sample_mean_salary <- mean(nfl_sample$YearlySalary)
nfl_sample_mean_salary
```

The average salary in the sample of 50 NFL players is 3.52 millions.

Without knowledge of the full data, we would say that we estimate the average salary of an NFL player in the year 2015 to be 3.52 millions.

:::yellow
**KEY QUESTION**

How precise is that estimate?
:::

### Confidence Interval

We do not want to report a single number as the estimate, as we know that our estimate will almost certainly differ from the true value of the population parameter. We probably want to be cautious and report a **range of plausible values** for the parameter, known as **confidence interval (CI)**, which is more likely to capture the true value of the parameter. See the following image for a summary of the idea:

```{r}
#| echo=FALSE,
#| fig.cap = "Source: moderndive.com"
knitr::include_graphics('https://d33wubrfki0l68.cloudfront.net/45f6d2e16255dbcb42de86336e1e49ef732aa5da/8bcd0/images/shutterstock/point_estimate_vs_conf_int.png')
```

<br>

To get the range of plausible values, we will use the fact that in a Normal distribution 95% of the values are roughly between the mean - 2 SD and the mean + 2 SD. See [here](1_10_continuous_distributions.html#The_68-95-997%_rule) for more details.

We know that the sample mean follows a normal distribution, and we also know that the standard deviation of the sampling distribution of the mean is also known as the __standard error__ (SE).

However, we cannot obtain the standard error of the mean as we do not have the data on the entire population. If we used the formula for the standard error, $SE = \sigma / \sqrt{n}$, we would need to know the population standard deviation $\sigma$ (which we don't). If we wanted to compute the SE by (a) repeatedly sampling from the population, (b) computing the mean on each sample, and (c) taking the standard deviation of the means, we still couldn't as we simply cannot repeatedly sample from the population: we only have ONE sample.

This week we investigate two methods for estimating the standard error of a statistic that only uses the original sample and as such is applicable when data on the entire population is not available.

  1. Theory-based SE and CI
  2. Bootstrap-based SE and CI


# 1. Theory-based SE and CI

This section investigates the so-called theory-based standard error and confidence interval. The name comes from the fact that no resampling is needed and a mathematical formula from probability theory is used to obtain the SE when the entire population data are not available.

Let $\mu$ be the population mean and $\sigma$ the population standard deviation. In [Week 11 of semester 1](1_11_sampling_distributions.Rmd) you saw that 

1. the sample mean $\bar X$ follows a normal distribution;
2. its average $\mu_{\overline X}$ is equal to the unknown population mean $\mu$; 
3. its standard deviation is equal to $\sigma_{\overline X} = SE = \sigma / \sqrt{n}$, also known as the standard error of the mean.

$$
\bar X \sim N(\mu_{\overline{X}}, \sigma_{\overline{X}}) \quad \text{where}
\quad \begin{cases}
\mu_{\overline{X}} = \mu \\
\sigma_{\overline{X}} = SE = \frac{\sigma}{\sqrt{n}}
\end{cases}
$$

Property 1 tells us that if we computed the sample mean on many samples from the population and created a histogram, this would be bell-shaped like a Normal distribution. So, __the sampling distribution of the mean is a Normal distribution.__

Property 2 tells us that the sampling distribution of the mean is centred at the unknown population mean $\mu$. So, on average our sample means are close to the true but unknown population mean.

Property 3 tells us that the spread (standard deviation) of the sampling distribution is $\sigma_{\overline X} = \sigma / \sqrt{n}$.


:::frame
__Finding the central 95% probability__  

Recall this image for a generic $X \sim N(\mu, \sigma)$ distribution:

```{r, echo=FALSE, out.width='70%'}
knitr::include_graphics('images/prob/normal_rule.png')
```

The middle 95% probability lies between the values $x = \mu - 2 \sigma$ and $x = \mu + 2 \sigma$.

To be more precise, the values between which lies the central 95% probability are those quantiles cutting 0.025 probability to the left and 0.025 probability to the right (= 0.975 to the left).

```{r}
qnorm(c(0.025, 0.975))   # note that: 0.975 - 0.025 = 0.95
```

Meaning that 95% of the values in a normal distribution are between

$$
[\mu - 1.96 \cdot \sigma, \ 
\mu + 1.96 \cdot \sigma]
$$
:::


Replacing $\mu$ and $\sigma$ with $\mu_{\overline X}$ and $\sigma_{\overline X}$ we obtain the 95% confidence interval for the sample mean $\bar X \sim N(\mu_{\overline X}, \sigma_{\overline X})$. That is, roughly 95% of the values are between

$$
[\mu_{\overline X} - 1.96 \cdot \sigma_{\overline X},\ 
\mu_{\overline X} + 1.96 \cdot \sigma_{\overline X}] 
$$

Substituting the formula for the $SE = \sigma_{\overline X} = \sigma / \sqrt{n}$, we know that 95% of the values are roughly between:

$$
\left[
\mu - 1.96 \cdot \frac{\sigma}{\sqrt n},\  
\mu + 1.96 \cdot \frac{\sigma}{\sqrt n}
\right]
$$

The formula above is the 95% confidence interval for the population mean.

<br>

There is one problem though... The confidence interval depends on $\mu$ and $\sigma$, the population mean salary and population standard deviation.

When we don't have the entire population data and we can only afford ONE sample, we do not have $\mu$ and we also do not have $\sigma$. We estimated $\mu$ with the sample mean $\bar x$, and we must also estimate $\sigma$ with the sample standard deviation $s$.

The standard error becomes:

$$
SE = \frac{s}{\sqrt n} \qquad \text{where } s = \text{sample standard deviation}
$$

and the confidence interval for the population mean becomes:

$$
\left[
\bar x - 1.96 \cdot \frac{s}{\sqrt n},\  
\bar x + 1.96 \cdot \frac{s}{\sqrt n}
\right]
$$

:::red
__However, that formula is not quite right!__ As we do not have the population standard deviation $\sigma$, we estimate it with the sample standard deviation $s$. This brings an extra element of uncertainty. 

Because we are unsure about the actual value of the population standard deviation, the resulting distribution is no longer Normal, but a distribution that is more "uncertain" and places higher probability in the tails of the distribution, meaning that larger or lower values could be observed with a higher chance.

When the population standard deviation is unknown, the sample mean follows a __t-distribution.__
:::


The t-distribution depends on a number called the **degrees of freedom** (DF) of the distribution, which is related to the sample size. The degrees of freedom are equal to the sample size - 1, i.e. $df = n - 1$. Because of this, we refer to the distribution of the sample mean as the $t(n-1)$ distribution.

t-distributions with smaller degrees of freedom (corresponding to smaller samples) put more probability on the tails of the distribution, meaning more uncertainty. As the degree of freedom increases, the t-distribution is indistinguishable from the Normal distribution, and this happens approximately with df $\geq$ 30.

```{r}
#| echo: FALSE
x = seq(-3, 3, 0.1)
yn = dnorm(x)
yt5 = dt(x, df = 5)
yt15 = dt(x, df = 15)
yt55 = dt(x, df = 55)
plot(x, yn, xlab = expr(bar(x)), ylab = "", type = 'l', col = 'black', frame.plot = F)
lines(x, yt5, col = 'red')
lines(x, yt15, col = 'green')
lines(x, yt55, col = 'blue')
legend(legend = c("Normal", "t(5)", "t(15)", "t(55)"),
       col = c('black', 'red', 'green', 'blue'),
       x = 'topright', lwd = c(1, 1, 1, 1))
```

Because the distribution has changed, we need to find the new values containing 95% of the probability. These are no longer -2 and 2 and will vary with the distribution.

Consider a sample of size $n = 10$. The corresponding df = 10 - 1 = 9. The values in between which lies the middle 0.95 probability are:

```{r}
# quantiles of a t-distribution with 9 df
qt(c(0.025, 0.975), df = 9)
```

These two values have, respectively, a probability of 0.025 to the left and 0.025 to the right.

Hence, for a t(9) distribution, 95% of the values are between:

$$
\left[
\bar x - 2.26 \cdot \frac{s}{\sqrt n}
,\  
\bar x + 2.26 \cdot \frac{s}{\sqrt n}
\right]
$$


:::frame
__Example__

Consider again the sample of 50 NFL players. We want to report not only an estimate for the mean salary, but also a range of plausible values, indicating the precision of our estimate.

```{r}
nfl_sample
```

We need a few elements according to our discussion above:

- $\bar{x}$, the sample mean which we already computed before
- $s$, the sample standard deviation
- $n$, the sample size
- the new multipliers to the SD based on the $t(n-1)$ distribution

```{r}
nfl_sample_mean_salary

nfl_sample_sd_salary <- sd(nfl_sample$YearlySalary)
nfl_sample_sd_salary

n <- nrow(nfl_sample)
n

qt(c(0.025, 0.975), df = n - 1)
```

The formula to use:

$$
\left[
\bar x - 2.01 \cdot \frac{s}{\sqrt n}
,\  
\bar x + 2.01 \cdot \frac{s}{\sqrt n}
\right]
$$

In R:

```{r}
nfl_sample_mean_salary - 2.01 * (nfl_sample_sd_salary / sqrt(n))
nfl_sample_mean_salary + 2.01 * (nfl_sample_sd_salary / sqrt(n))
```

The 95% confidence interval is then [2.21, 4.83] million dollars. We would write this up as:

:::int
We are 95% confident that the average salary of a NFL player in 2015 is between 2.21 and 4.83 million dollars.
:::

:::


# 2. Bootstrap-based SE and CI

Since this section involves sampling, I will set the random seed for reproducibility.

```{r}
set.seed(9876)
```

Recall today's setting: we only have ONE sample, and as such we do not have the sampling distribution and we do not have the standard error. We will now discuss another approach to find the standard error. The answer is **bootstrap!**

When the full population data is available, the sampling distribution is constructed by evaluating the sample mean on many samples from the population.

When only ONE sample is available, rather than the population, we repeatedly sample WITH REPLACEMENT from the original sample, using the same sample size as the original sample.

The idea is that the population is made up of many, many copies of the elements in the sample. Sampling with replacement from the original sample is equivalent to creating an imaginary population consisting of many copies of that sample, and then repeatedly sampling from the imaginary population.

```{r}
#| echo=FALSE,
#| out.width = '70%'
knitr::include_graphics('images/bootstrap_cis/boot_intuition.png')
```


:::frame
__Example__

Let `S` be the sample and `P` the imaginary population consisting of (say 50) repetitions of the original sample:

```{r}
S = tibble(salary = c(11, 55, 88))
S

P = tibble(salary = rep(c(11, 55, 88), 50))
P
```

If we sample from P, we can get repeated values:

```{r}
source('https://uoepsy.github.io/files/rep_sample_n.R')

rep_sample_n(P, n = 3)
rep_sample_n(P, n = 3)
```

Which is the same as sampling with replacement. That is, once a value is chosen, it is "put back" in the sample and it can be picked again. To sample with replacement add the argument `replace = TRUE` to the rep_sample_n function:

```{r}
rep_sample_n(S, n = 3, replace = TRUE)
rep_sample_n(S, n = 3, replace = TRUE)
```

If we sampled without replacement, we would always end up with the original sample. In fact, if 11 was picked, for the remaining 2 value we could only pick 55 or 88. If 88 was picked next, we would only be left with 55 for the last value leading us to a sample of 11, 88, 55.

```{r}
rep_sample_n(S, n = 3, replace = FALSE)
rep_sample_n(S, n = 3, replace = FALSE)
```


:::



:::yellow  
**Bootstrap sample**  

A bootstrap sample is obtained by

a. random sampling from the original sample
b. with replacement
c. using the same sample size as the original sample
:::



Now, we approximate the sampling distribution with a boostrap distribution, which is constructed by evaluating the sample mean on many bootstrap samples.

The steps to estimate an unknown population mean $\mu$ are the following:

1. Collect a sample and use the sample mean $\bar x$ as the estimate
1. Obtain many bootstrap samples
1. Obtain the bootstrap means by computing the mean of each bootstrap sample
1. The bootstrap SE is the standard deviation of the bootstrap means

:::frame
__Example__

1. Collect a sample and compute the sample mean. We have already done this before:
```{r message=FALSE}
nfl_sample
nfl_sample_mean_salary
```

2. Obtain many bootstrap samples and compute the bootstrap means
```{r}
nfl_boot_samples <- nfl_sample %>%
  rep_sample_n(n = 50, samples = 1000, replace = TRUE)

nfl_boot_samples
```

3. Compute the bootstrap means
```{r}
nfl_boot_means <- nfl_boot_samples %>%
    group_by(sample) %>%
    summarise(mean_salary = mean(YearlySalary))

nfl_boot_means
```

4. Compute the bootstrap SE

```{r}
nfl_boot_se <- sd(nfl_boot_means$mean_salary)

nfl_boot_se
```
:::


Let's visualise the bootstrap distribution

```{r}
ggplot(nfl_boot_means, aes(x = mean_salary)) +
    geom_histogram(color = 'white')
```


- The standard deviation of the bootstrap distribution is the bootstrap standard error.

- The bootstrap distribution is an approximation to the sampling distribution (which we cannot obtain)

:::red
__Warning__

- The average of the bootstrap distribution is the sample statistic!

- This is different from the average of the sampling distribution, which is the population parameter.

```{r}
mean(nfl_boot_means$mean_salary)
nfl_sample_mean_salary
```

:::


:::frame 
#### Interpreting a confidence interval?

If we were to do this whole process over and over again: 

+ take a random sample of size $n$;
+ sample with replacement from that sample;
+ construct a 95% confidence interval.

Then about 95% of the confidence intervals we created would contain the population mean.  

So if we did this 100 times, we would expect about five of our 95% confidence intervals to not contain the true population mean. 

And if we had been constructing 80% confidence intervals instead, we would expect roughly 80 of them to contain the population mean.  
:::


## Bootstrap CI

We can construct a bootstrap confidence interval using two approaches.

### 1. Using the bootstrap SE

This requires us to find the relevant multipliers from the t-distribution, and use the bootstrap standard error:

$$
[\bar{x} - t^* \cdot SE,\  \bar{x} + t^* \cdot SE]
$$

The quantiles of the t-distribution are:

```{r}
qt(c(0.025, 0.975), df = 49)
```

And the confidence interval is:

```{r}
nfl_sample_mean_salary - 2.01 * nfl_boot_se
nfl_sample_mean_salary + 2.01 * nfl_boot_se
```

:::int
We are 95% confident that the average salary of a NFL player in 2015 is between 2.24 and 4.80 million dollars.
:::

### 2. Using the percentiles of the bootstrap distribution

We can directly find the quantiles of the bootstrap distribution that have 0.025 probability to the left and 0.025 probability to the right, i.e. 0.95 in between them.

Because we are not using a probability distribution, but data we computed, we must use the `quantile()` function. This takes the data as first argument, and the probabilities as second.

```{r}
quantile(nfl_boot_means$mean_salary, probs = c(0.025, 0.975))
```

:::int
We are 95% confident that the average salary of a NFL player in 2015 is between 2.35 and 4.84 million dollars.
:::



# Glossary

- *Population.* The entire collection of units of interest.
- *Sample.* A subset of the entire population.
- *Parameter.* A fixed but typically unknown quantity describing the population.
- *Statistic.* A quantity computed on a sample.
- *Sampling distribution.* The distribution of the values that a statistic takes on different samples of the same size and from the same population.
- *Standard error.* The standard error of a statistic is the standard deviation of the sampling distribution of the statistic.

- *Resample.* To sample again from your original sample
- *Bootstrapping.* Repeated random sampling with replacement
- *Bootstrap distribution.* The distribution of statistics calculated on random **re**samples. Approximates the sampling distribution of the sample statistic.
- *Confidence interval (CI).* A range of plausible values around an estimate (e.g., a sample statistic), taking into account uncertainty in the statistic (e.g., sampling variability)
- *Confidence level.* The percentage of confidence intervals which will contain the true population parameter **in the long run** (i.e., if you sampled the population and constructed confidence intervals many times over). The proportion of all samples whose intervals contain the true parameter.


# Exercises 

:::red
**Remember** you will need to "source" the `rep_sample_n()` function into your environment. 
Paste this code and make sure it appears in the top-right pane of RStudio. 
```{r}
source('https://uoepsy.github.io/files/rep_sample_n.R')
```
:::


## A. Hollywood Movies

The following code chunk reads in a **sample** of the Hollywood movies data we saw last week. 
```{r, message=FALSE}
hollywood_sample <- read_csv("https://uoepsy.github.io/data/hollywoodsample1.csv")
```


`r qbegin(1)`
This week, we're interested in the average Rotten Tomatoes rating for all Hollywood movies between 2007 and 2013.   
What is our best estimate of this with the data we just read in?
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
$\bar{x}$, the mean Rotten Tomatoes rating for our sample.

```{r}
hollywood_sample %>% 
  summarise(avg_rating = mean(RottenTomatoes))
```
`r solend()`

`r qbegin(2)`
Generate 2000 bootstrap resamples to create the bootstrap distribution. Store it as an object in R with the name `hollywood_bs`.  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
hollywood_bs <- 
  rep_sample_n(hollywood_sample, n = 25, samples = 2000, replace = TRUE) %>%
  group_by(sample) %>%
  summarise(avg_rating = mean(RottenTomatoes))
```
`r solend()`

`r qbegin(3)`
Estimate the standard error of the sample statistic from your bootstrap distribution.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
hollywood_bs %>%
  summarise(estimated_SE = sd(avg_rating))
```
or 
```{r}
sd(hollywood_bs$avg_rating)
```

`r solend()`

`r qbegin(4)`
Compute the 95% confidence intervals around our estimate of the average Rotten Tomatoes rating, and plot the bootstrap distribution and the confidence interval.  

*Hint*: `geom_vline()`. 
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
n <- nrow(hollywood_sample)
qt(c(0.025, 0.975), df = n-1)
hwood_ci_lower <- mean(hollywood_sample$RottenTomatoes) - 2.06 * sd(hollywood_bs$avg_rating)
hwood_ci_upper <- mean(hollywood_sample$RottenTomatoes) + 2.06 * sd(hollywood_bs$avg_rating)

ggplot(hollywood_bs, aes(x=avg_rating)) +
  geom_histogram() +
  geom_vline(xintercept = c(hwood_ci_lower, hwood_ci_upper)) +
  labs(x = "bootstrap avg rating")
```
`r solend()`

`r qbegin(5)`
Here is a new sample, but this time it contains 50 movies. Do the same (estimate the mean and construct a confidence interval). How does the confidence interval differ from the one created for a sample of 25?  
```{r}
hollywood_sample2 <- read_csv("https://uoepsy.github.io/data/hollywoodsample2.csv")
```

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
hollywood_sample2 <- read_csv("https://uoepsy.github.io/data/hollywoodsample2.csv")

hollywood_bs <- 
  rep_sample_n(hollywood_sample2, n = 50, samples = 2000, replace = TRUE) %>%
  group_by(sample) %>%
  summarise(avg_rating = mean(RottenTomatoes))

n <- nrow(hollywood_sample2)
qt(c(0.025, 0.975), df = n - 1)
mean(hollywood_sample2$RottenTomatoes) - 2.01 * sd(hollywood_bs$avg_rating)
mean(hollywood_sample2$RottenTomatoes) + 2.01 * sd(hollywood_bs$avg_rating)
```
`r solend()`

`r qbegin(6)`
*Using the theory-based approach for the standard error*, construct 95% **and 99%**  confidence intervals around the mean Rotten Tomatoes rating based on the sample of 50 movies.  
  
Given that for the 99% confidence interval we will have *greater* confidence that it will contain the true population parameter than the 95% confidence interval, do we expect the range to be bigger or smaller? 
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
We are more confident in wider ranges, so the 99% CI will be wider.  

Example:  

- imagine you are trying to guess my age. 
- how confident are you that I am between 25 and 35 years old? 
- how confident are you that I am between 10 and 50 years old?
- how confident are you that I am between 29 and 31 years old?
- how confident are you that I am between 0 and 1000 years old?  

```{r}
qt(c(0.025, 0.975), df = n-1)
mean(hollywood_sample2$RottenTomatoes) - 2.01 * (sd(hollywood_sample2$RottenTomatoes)/sqrt(n))
mean(hollywood_sample2$RottenTomatoes) + 2.01 * (sd(hollywood_sample2$RottenTomatoes)/sqrt(n))

qt(c(0.005, 0.995), df = n-1)
mean(hollywood_sample2$RottenTomatoes) - 2.68 * (sd(hollywood_sample2$RottenTomatoes)/sqrt(n))
mean(hollywood_sample2$RottenTomatoes) + 2.68 * (sd(hollywood_sample2$RottenTomatoes)/sqrt(n))
```
`r solend()`


## B. NFL Players

`r qbegin(7)`
Scroll back up - what was the **population** mean yearly salary for all NFL players at the beginning of 2015? 
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r, message=F}
nfl_pop <- read_csv("https://uoepsy.github.io/data/nflpop.csv")
mean(nfl_pop$YearlySalary)
```

`r mean(nfl_pop$YearlySalary) %>% round(2)` (million dollars!!)
`r solend()`

`r qbegin(8)`
A researcher lives in Boston. They want to estimate salaries of NFL players, and in 2015 they go around and ask 50 players about their yearly salaries.  
The code below reads in the sample they collected.
```{r message=FALSE}
nfl_boston <- read_csv("https://uoepsy.github.io/data/nflboston.csv")
```
Compute the sample mean, and calculate 95% confidence intervals via bootstrap standard error
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
nfl_bs <- rep_sample_n(nfl_boston, n = 50, samples = 2000, replace = TRUE) %>%
  group_by(sample) %>%
  summarise(avg_salary = mean(YearlySalary))

qt(c(0.025, 0.975), df = 49)
mean(nfl_boston$YearlySalary) - 2.01 * sd(nfl_bs$avg_salary)
mean(nfl_boston$YearlySalary) + 2.01 * sd(nfl_bs$avg_salary)
```
`r solend()`

`r qbegin(9)`
This confidence does not include the population mean of `r mean(nfl_pop$YearlySalary) %>% round(2)`. Why not?  

```{r}
ggplot(nfl_bs, aes(x=avg_salary)) +
  geom_histogram() +
  labs(x = "bootstrap avg salary (millions of $)\nbased on bootstrapped Boston sample") +
  geom_vline(xintercept = mean(nfl_pop$YearlySalary))+
  geom_text(x=3.05, y=150,label="True population mean",hjust=0)+
  geom_vline(xintercept = c(mean(nfl_boston$YearlySalary) - 1.96 * sd(nfl_bs$avg_salary), mean(nfl_boston$YearlySalary) + 1.96 * sd(nfl_bs$avg_salary)), col="tomato1")
```


*Hint:* Look at your data, and think about what you know about how it was collected - why might this not be a good sample?
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
The researcher, living in Boston, seems to have sampled a lot of players from the New England Patriots (a local team).  

The key thing here is that the statistical inference we are making (that the sample mean is an estimate of the population mean) *assumes* that the sample is an unbiased representation. In this case it is not a truly random sample!
`r solend()`



<!-- Formatting -->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>


